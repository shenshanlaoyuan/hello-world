<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>深山老猿</title>
  <icon>https://www.gravatar.com/avatar/337c5b9715d60466924c746da7df8603</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://shenshanlaoyuan.com/"/>
  <updated>2020-05-29T03:08:54.450Z</updated>
  <id>http://shenshanlaoyuan.com/</id>
  
  <author>
    <name>深山老猿</name>
    <email>wl4j@foxmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>为什么要进行系统拆分？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/29/%E9%9D%A2%E8%AF%95/2020-5-29-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E7%B3%BB%E7%BB%9F%E6%8B%86%E5%88%86%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/29/面试/2020-5-29-为什么要进行系统拆分？/</id>
    <published>2020-05-29T03:52:00.000Z</published>
    <updated>2020-05-29T03:08:54.450Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>从这个问题开始就进行分布式系统环节了，现在出去面试分布式都成标配了，没有哪个公司不问问你分布式的事儿。你要是不会分布式的东西，简直这简历没法看，没人会让你去面试。</p><p>其实为啥会这样呢？这就是因为整个大行业技术发展的原因。</p><p>早些年，印象中在 2010 年初的时候，整个 IT 行业，很少有人谈分布式，更不用说微服务，虽然很多 BAT 等大型公司，因为系统的复杂性，很早就是分布式架构，大量的服务，只不过微服务大多基于自己搞的一套框架来实现而已。</p><p>但是确实，那个年代，大家很重视 ssh2，很多中小型公司几乎大部分都是玩儿 struts2、spring、hibernate，稍晚一些，才进入了 spring mvc、spring、mybatis 的组合。那个时候整个行业的技术水平就是那样，当年 oracle 很火，oracle 管理员很吃香，oracle 性能优化啥的都是 IT 男的大杀招啊。连大数据都没人提，当年 OCP、OCM 等认证培训机构，火的不行。</p><p>但是确实随着时代的发展，慢慢的，很多公司开始接受分布式系统架构了，这里面尤为对行业有至关重要影响的，是阿里的 dubbo，<strong>某种程度上而言，阿里在这里推动了行业技术的前进</strong>。</p><p>正是因为有阿里的 dubbo，很多中小型公司才可以基于 dubbo，来把系统拆分成很多的服务，每个人负责一个服务，大家的代码都没有冲突，服务可以自治，自己选用什么技术都可以，每次发布如果就改动一个服务那就上线一个服务好了，不用所有人一起联调，每次发布都是几十万行代码，甚至几百万行代码了。</p><p>直到今日，很高兴看到分布式系统都成行业面试标配了，任何一个普通的程序员都该掌握这个东西，其实这是行业的进步，也是所有 IT 码农的技术进步。所以既然分布式都成标配了，那么面试官当然会问了，因为很多公司现在都是分布式、微服务的架构，那面试官当然得考察考察你了。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/29/面试/2020-5-29-为什么要进行系统拆分？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/29/面试/2020-5-29-为什么要进行系统拆分？/'>为什么要进行系统拆分？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么要将系统进行拆分？"><a href="#为什么要将系统进行拆分？" class="headerlink" title="为什么要将系统进行拆分？"></a>为什么要将系统进行拆分？</h3><p>网上查查，答案极度零散和复杂，很琐碎，原因一大坨。但是我这里给大家直观的感受：</p><p>要是<strong>不拆分</strong>，一个大系统几十万行代码，20 个人维护一份代码，简直是悲剧啊。代码经常改着改着就冲突了，各种代码冲突和合并要处理，非常耗费时间；经常我改动了我的代码，你调用了我的，导致你的代码也得重新测试，麻烦的要死；然后每次发布都是几十万行代码的系统一起发布，大家得一起提心吊胆准备上线，几十万行代码的上线，可能每次上线都要做很多的检查，很多异常问题的处理，简直是又麻烦又痛苦；而且如果我现在打算把技术升级到最新的 spring 版本，还不行，因为这可能导致你的代码报错，我不敢随意乱改技术。</p><p>假设一个系统是 20 万行代码，其中 A 在里面改了 1000 行代码，但是此时发布的时候是这个 20 万行代码的大系统一块儿发布。就意味着 20 万上代码在线上就可能出现各种变化，20 个人，每个人都要紧张地等在电脑面前，上线之后，检查日志，看自己负责的那一块儿有没有什么问题。</p><p>A 就检查了自己负责的 1 万行代码对应的功能，确保 ok 就闪人了；结果不巧的是，A 上线的时候不小心修改了线上机器的某个配置，导致另外 B 和 C 负责的 2 万行代码对应的一些功能，出错了。</p><p>几十个人负责维护一个几十万行代码的单块应用，每次上线，准备几个礼拜，上线 -&gt; 部署 -&gt; 检查自己负责的功能。</p><p><strong>拆分了以后</strong>，整个世界清爽了，几十万行代码的系统，拆分成 20 个服务，平均每个服务就 1~2 万行代码，每个服务部署到单独的机器上。20 个工程，20 个 git 代码仓库，20 个开发人员，每个人维护自己的那个服务就可以了，是自己独立的代码，跟别人没关系。再也没有代码冲突了，爽。每次就测试我自己的代码就可以了，爽。每次就发布我自己的一个小服务就可以了，爽。技术上想怎么升级就怎么升级，保持接口不变就可以了，真爽。</p><p>所以简单来说，一句话总结，如果是那种代码量多达几十万行的中大型项目，团队里有几十个人，那么如果不拆分系统，<strong>开发效率极其低下</strong>，问题很多。但是拆分系统之后，每个人就负责自己的一小部分就好了，可以随便玩儿随便弄。分布式系统拆分之后，可以大幅度提升复杂系统大型团队的开发效率。</p><p>但是同时，也要<strong>提醒</strong>的一点是，系统拆分成分布式系统之后，大量的分布式系统面临的问题也是接踵而来，所以后面的问题都是在<strong>围绕分布式系统带来的复杂技术挑战</strong>在说。</p><h3 id="如何进行系统拆分？"><a href="#如何进行系统拆分？" class="headerlink" title="如何进行系统拆分？"></a>如何进行系统拆分？</h3><p>这个问题说大可以很大，可以扯到领域驱动模型设计上去，说小了也很小，我不太想给大家太过于学术的说法，因为你也不可能背这个答案，过去了直接说吧。还是说的简单一点，大家自己到时候知道怎么回答就行了。</p><p>系统拆分为分布式系统，拆成多个服务，拆成微服务的架构，是需要拆很多轮的。并不是说上来一个架构师一次就给拆好了，而以后都不用拆。</p><p>第一轮；团队继续扩大，拆好的某个服务，刚开始是 1 个人维护 1 万行代码，后来业务系统越来越复杂，这个服务是 10 万行代码，5 个人；第二轮，1个服务 -&gt; 5个服务，每个服务 2 万行代码，每人负责一个服务。</p><p>如果是多人维护一个服务，最理想的情况下，几十个人，1 个人负责 1 个或 2~3 个服务；某个服务工作量变大了，代码量越来越多，某个同学，负责一个服务，代码量变成了 10 万行了，他自己不堪重负，他现在一个人拆开，5 个服务，1 个人顶着，负责 5 个人，接着招人，2 个人，给那个同学带着，3 个人负责 5 个服务，其中 2 个人每个人负责 2 个服务，1 个人负责 1 个服务。</p><p>个人建议，一个服务的代码不要太多，1 万行左右，两三万撑死了吧。</p><p>大部分的系统，是要进行<strong>多轮拆分</strong>的，第一次拆分，可能就是将以前的多个模块该拆分开来了，比如说将电商系统拆分成订单系统、商品系统、采购系统、仓储系统、用户系统，等等吧。</p><p>但是后面可能每个系统又变得越来越复杂了，比如说采购系统里面又分成了供应商管理系统、采购单管理系统，订单系统又拆分成了购物车系统、价格系统、订单管理系统。</p><p>扯深了实在很深，所以这里先给大家举个例子，你自己感受一下，<strong>核心意思就是根据情况，先拆分一轮，后面如果系统更复杂了，可以继续分拆</strong>。你根据自己负责系统的例子，来考虑一下就好了。</p><h3 id="拆分后不用-dubbo-可以吗？"><a href="#拆分后不用-dubbo-可以吗？" class="headerlink" title="拆分后不用 dubbo 可以吗？"></a>拆分后不用 dubbo 可以吗？</h3><p>当然可以了，大不了最次，就是各个系统之间，直接基于 spring mvc，就纯 http 接口互相通信呗，还能咋样。但是这个肯定是有问题的，因为 http 接口通信维护起来成本很高，你要考虑<strong>超时重试</strong>、<strong>负载均衡</strong>等等各种乱七八糟的问题，比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。</p><p>所以 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡、服务实例上下线自动感知、超时重试等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;从这个问题开始就进行分布式系统环节了，现在出去面试分布式都成标配了，没有哪个公司不问问你分布式的事儿。你要是不会分布式的东西，简直这简历没法看，没人会让你去面试。&lt;/p&gt;
&lt;p&gt;其实为啥会这样呢？这就是因为整个大行业技术发展的原因。&lt;/p&gt;
&lt;p&gt;早些年，印象中在 2010 年初的时候，整个 IT 行业，很少有人谈分布式，更不用说微服务，虽然很多 BAT 等大型公司，因为系统的复杂性，很早就是分布式架构，大量的服务，只不过微服务大多基于自己搞的一套框架来实现而已。&lt;/p&gt;
&lt;p&gt;但是确实，那个年代，大家很重视 ssh2，很多中小型公司几乎大部分都是玩儿 struts2、spring、hibernate，稍晚一些，才进入了 spring mvc、spring、mybatis 的组合。那个时候整个行业的技术水平就是那样，当年 oracle 很火，oracle 管理员很吃香，oracle 性能优化啥的都是 IT 男的大杀招啊。连大数据都没人提，当年 OCP、OCM 等认证培训机构，火的不行。&lt;/p&gt;
&lt;p&gt;但是确实随着时代的发展，慢慢的，很多公司开始接受分布式系统架构了，这里面尤为对行业有至关重要影响的，是阿里的 dubbo，&lt;strong&gt;某种程度上而言，阿里在这里推动了行业技术的前进&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;正是因为有阿里的 dubbo，很多中小型公司才可以基于 dubbo，来把系统拆分成很多的服务，每个人负责一个服务，大家的代码都没有冲突，服务可以自治，自己选用什么技术都可以，每次发布如果就改动一个服务那就上线一个服务好了，不用所有人一起联调，每次发布都是几十万行代码，甚至几百万行代码了。&lt;/p&gt;
&lt;p&gt;直到今日，很高兴看到分布式系统都成行业面试标配了，任何一个普通的程序员都该掌握这个东西，其实这是行业的进步，也是所有 IT 码农的技术进步。所以既然分布式都成标配了，那么面试官当然会问了，因为很多公司现在都是分布式、微服务的架构，那面试官当然得考察考察你了。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>如何设计一个高并发系统？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/28/%E9%9D%A2%E8%AF%95/2020-5-28-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/28/面试/2020-5-28-如何设计一个高并发系统？/</id>
    <published>2020-05-28T03:52:00.000Z</published>
    <updated>2020-05-29T03:07:38.241Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何设计一个高并发系统？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>说实话，如果面试官问你这个题目，那么你必须要使出全身吃奶劲了。为啥？因为你没看到现在很多公司招聘的 JD 里都是说啥，有高并发就经验者优先。</p><p>如果你确实有真才实学，在互联网公司里干过高并发系统，那你确实拿 offer 基本如探囊取物，没啥问题。面试官也绝对不会这样来问你，否则他就是蠢。</p><p>假设你在某知名电商公司干过高并发系统，用户上亿，一天流量几十亿，高峰期并发量上万，甚至是十万。那么人家一定会仔细盘问你的系统架构，你们系统啥架构？怎么部署的？部署了多少台机器？缓存咋用的？MQ 咋用的？数据库咋用的？就是深挖你到底是如何扛住高并发的。</p><p>因为真正干过高并发的人一定知道，脱离了业务的系统架构都是在纸上谈兵，真正在复杂业务场景而且还高并发的时候，那系统架构一定不是那么简单的，用个 redis，用 mq 就能搞定？当然不是，真实的系统架构搭配上业务之后，会比这种简单的所谓“高并发架构”要复杂很多倍。</p><p>如果有面试官问你个问题说，如何设计一个高并发系统？那么不好意思，<strong>一定是因为你实际上没干过高并发系统</strong>。面试官看你简历就没啥出彩的，感觉就不咋地，所以就会问问你，如何设计一个高并发系统？其实说白了本质就是看看你有没有自己研究过，有没有一定的知识积累。</p><p>最好的当然是招聘个真正干过高并发的哥儿们咯，但是这种哥儿们人数稀缺，不好招。所以可能次一点的就是招一个自己研究过的哥儿们，总比招一个啥也不会的哥儿们好吧！</p><p>所以这个时候你必须得做一把个人秀了，秀出你所有关于高并发的知识！</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/28/面试/2020-5-28-如何设计一个高并发系统？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/28/面试/2020-5-28-如何设计一个高并发系统？/'>如何设计一个高并发系统？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实所谓的高并发，如果你要理解这个问题呢，其实就得从高并发的根源出发，为啥会有高并发？为啥高并发就很牛逼？</p><p>我说的浅显一点，很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p><p>当然会挂了，凭什么不挂？你数据库如果瞬间承载每秒 5000/8000，甚至上万的并发，一定会宕机，因为比如 mysql 就压根儿扛不住这么高的并发量。</p><p>所以为啥高并发牛逼？就是因为现在用互联网的人越来越多，很多 app、网站、系统承载的都是高并发请求，可能高峰期每秒并发量几千，很正常的。如果是什么双十一之类的，每秒并发几万几十万都有可能。</p><p>那么如此之高的并发量，加上原本就如此之复杂的业务，咋玩儿？真正厉害的，一定是在复杂业务系统里玩儿过高并发架构的人，但是你没有，那么我给你说一下你该怎么回答这个问题：</p><p>可以分为以下 6 点：</p><ul><li>系统拆分</li><li>缓存</li><li>MQ</li><li>分库分表</li><li>读写分离</li><li>ElasticSearch</li></ul><p><img src="https://i.loli.net/2020/05/28/UMDAq4sXIW6ybiQ.png" alt="high-concurrency-system-design.png"></p><h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是<strong>读多写少</strong>，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的<strong>读场景，怎么用缓存来抗高并发</strong>。</p><h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，<strong>后边系统消费后慢慢写</strong>，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表<strong>拆分为多个表</strong>，每个表的数据量保持少一点，提高 sql 跑的性能。</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，<strong>主库写</strong>入，<strong>从库读</strong>取，搞一个读写分离。<strong>读流量太多</strong>的时候，还可以<strong>加更多的从库</strong>。</p><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 es。es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p><p>上面的 6 点，基本就是高并发系统肯定要干的一些事儿，大家可以仔细结合之前讲过的知识考虑一下，到时候你可以系统的把这块阐述一下，然后每个部分要注意哪些问题，之前都讲过了，你都可以阐述阐述，表明你对这块是有点积累的。</p><p>说句实话，毕竟你真正厉害的一点，不是在于弄明白一些技术，或者大概知道一个高并发系统应该长什么样？其实实际上在真正的复杂的业务系统里，做高并发要远远比上面提到的点要复杂几十倍到上百倍。你需要考虑：哪些需要分库分表，哪些不需要分库分表，单库单表跟分库分表如何 join，哪些数据要放到缓存里去，放哪些数据才可以扛住高并发的请求，你需要完成对一个复杂业务系统的分析之后，然后逐步逐步的加入高并发的系统架构的改造，这个过程是无比复杂的，一旦做过一次，并且做好了，你在这个市场上就会非常的吃香。</p><p>其实大部分公司，真正看重的，不是说你掌握高并发相关的一些基本的架构知识，架构中的一些技术，RocketMQ、Kafka、Redis、Elasticsearch，高并发这一块，你了解了，也只能是次一等的人才。对一个有几十万行代码的复杂的分布式系统，一步一步架构、设计以及实践过高并发架构的人，这个经验是难能可贵的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何设计一个高并发系统？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;说实话，如果面试官问你这个题目，那么你必须要使出全身吃奶劲了。为啥？因为你没看到现在很多公司招聘的 JD 里都是说啥，有高并发就经验者优先。&lt;/p&gt;
&lt;p&gt;如果你确实有真才实学，在互联网公司里干过高并发系统，那你确实拿 offer 基本如探囊取物，没啥问题。面试官也绝对不会这样来问你，否则他就是蠢。&lt;/p&gt;
&lt;p&gt;假设你在某知名电商公司干过高并发系统，用户上亿，一天流量几十亿，高峰期并发量上万，甚至是十万。那么人家一定会仔细盘问你的系统架构，你们系统啥架构？怎么部署的？部署了多少台机器？缓存咋用的？MQ 咋用的？数据库咋用的？就是深挖你到底是如何扛住高并发的。&lt;/p&gt;
&lt;p&gt;因为真正干过高并发的人一定知道，脱离了业务的系统架构都是在纸上谈兵，真正在复杂业务场景而且还高并发的时候，那系统架构一定不是那么简单的，用个 redis，用 mq 就能搞定？当然不是，真实的系统架构搭配上业务之后，会比这种简单的所谓“高并发架构”要复杂很多倍。&lt;/p&gt;
&lt;p&gt;如果有面试官问你个问题说，如何设计一个高并发系统？那么不好意思，&lt;strong&gt;一定是因为你实际上没干过高并发系统&lt;/strong&gt;。面试官看你简历就没啥出彩的，感觉就不咋地，所以就会问问你，如何设计一个高并发系统？其实说白了本质就是看看你有没有自己研究过，有没有一定的知识积累。&lt;/p&gt;
&lt;p&gt;最好的当然是招聘个真正干过高并发的哥儿们咯，但是这种哥儿们人数稀缺，不好招。所以可能次一点的就是招一个自己研究过的哥儿们，总比招一个啥也不会的哥儿们好吧！&lt;/p&gt;
&lt;p&gt;所以这个时候你必须得做一把个人秀了，秀出你所有关于高并发的知识！&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="高并发" scheme="http://shenshanlaoyuan.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>如何实现 MySQL 的读写分离？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/27/%E9%9D%A2%E8%AF%95/2020-5-27-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0-MySQL-%E7%9A%84%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/27/面试/2020-5-27-如何实现-MySQL-的读写分离？/</id>
    <published>2020-05-27T03:52:00.000Z</published>
    <updated>2020-05-29T03:06:12.495Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>高并发这个阶段，肯定是需要做读写分离的，啥意思？因为实际上大部分的互联网公司，一些网站，或者是 app，其实都是读多写少。所以针对这个情况，就是写一个主库，但是主库挂多个从库，然后从多个从库来读，那不就可以支撑更高的读并发压力了吗？</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/27/面试/2020-5-27-如何实现-MySQL-的读写分离？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/27/面试/2020-5-27-如何实现-MySQL-的读写分离？/'>如何实现 MySQL 的读写分离？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="如何实现-MySQL-的读写分离？"><a href="#如何实现-MySQL-的读写分离？" class="headerlink" title="如何实现 MySQL 的读写分离？"></a>如何实现 MySQL 的读写分离？</h3><p>其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。</p><h3 id="MySQL-主从复制原理的是啥？"><a href="#MySQL-主从复制原理的是啥？" class="headerlink" title="MySQL 主从复制原理的是啥？"></a>MySQL 主从复制原理的是啥？</h3><p>主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。</p><p><img src="https://s1.ax1x.com/2020/05/28/tVTghj.png" alt="tVTghj.png"></p><p>这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是<strong>有延时</strong>的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。</p><p>而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。</p><p>所以 MySQL 实际上在这一块有两个机制，一个是<strong>半同步复制</strong>，用来解决主库数据丢失问题；一个是<strong>并行复制</strong>，用来解决主从同步延时问题。</p><p>这个所谓<strong>半同步复制</strong>，也叫 <code>semi-sync</code> 复制，指的就是主库写入 binlog 日志之后，就会将<strong>强制</strong>此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到<strong>至少一个从库</strong>的 ack 之后才会认为写操作完成了。</p><p>所谓<strong>并行复制</strong>，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后<strong>并行重放不同库的日志</strong>，这是库级别的并行。</p><h3 id="MySQL-主从同步延时问题（精华）"><a href="#MySQL-主从同步延时问题（精华）" class="headerlink" title="MySQL 主从同步延时问题（精华）"></a>MySQL 主从同步延时问题（精华）</h3><p>以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。</p><p>是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。</p><p>我们通过 MySQL 命令：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">show</span> <span class="keyword">status</span></div></pre></td></tr></table></figure></p><p>查看 <code>Seconds_Behind_Master</code>，可以看到从库复制主库的数据落后了几 ms。</p><p>一般来说，如果主从延迟较为严重，有以下解决方案：</p><ul><li>分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。</li><li>打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。</li><li>重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。</li><li>如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询<strong>设置直连主库</strong>。<strong>不推荐</strong>这种方法，你要是这么搞，读写分离的意义就丧失了。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;高并发这个阶段，肯定是需要做读写分离的，啥意思？因为实际上大部分的互联网公司，一些网站，或者是 app，其实都是读多写少。所以针对这个情况，就是写一个主库，但是主库挂多个从库，然后从多个从库来读，那不就可以支撑更高的读并发压力了吗？&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="MYSQL" scheme="http://shenshanlaoyuan.com/tags/MYSQL/"/>
    
      <category term="读写分离" scheme="http://shenshanlaoyuan.com/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    
  </entry>
  
  <entry>
    <title>分库分表之后，id 主键如何处理？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/26/%E9%9D%A2%E8%AF%95/2020-5-26-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%B9%8B%E5%90%8E%EF%BC%8Cid-%E4%B8%BB%E9%94%AE%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/26/面试/2020-5-26-分库分表之后，id-主键如何处理？/</id>
    <published>2020-05-26T03:52:00.000Z</published>
    <updated>2020-05-29T03:04:39.567Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>分库分表之后，id 主键如何处理？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个<strong>全局唯一</strong>的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/26/面试/2020-5-26-分库分表之后，id-主键如何处理？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/26/面试/2020-5-26-分库分表之后，id-主键如何处理？/'>分库分表之后，id 主键如何处理？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="基于数据库的实现方案"><a href="#基于数据库的实现方案" class="headerlink" title="基于数据库的实现方案"></a>基于数据库的实现方案</h3><h4 id="数据库自增-id"><a href="#数据库自增-id" class="headerlink" title="数据库自增 id"></a>数据库自增 id</h4><p>这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。</p><p>这个方案的好处就是方便简单，谁都会用；<strong>缺点就是单库生成</strong>自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是<strong>无论如何都是基于单个数据库</strong>。</p><p><strong>适合的场景</strong>：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你<strong>并发不高，但是数据量太大</strong>导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。</p><h4 id="设置数据库-sequence-或者表自增字段步长"><a href="#设置数据库-sequence-或者表自增字段步长" class="headerlink" title="设置数据库 sequence 或者表自增字段步长"></a>设置数据库 sequence 或者表自增字段步长</h4><p>可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。</p><p>比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。</p><p><img src="https://i.loli.net/2020/05/28/xhX5yzpwB4QN9M3.png" alt="database-id-sequence-step.png"></p><p><strong>适合的场景</strong>：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。</p><h3 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h3><p>好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，<strong>作为主键性能太差</strong>了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。</p><p>适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">UUID.randomUUID().toString().replace(<span class="string">"-"</span>, <span class="string">""</span>) -&gt; sfsdf23423rr234sfdaf</div></pre></td></tr></table></figure><h3 id="获取系统当前时间"><a href="#获取系统当前时间" class="headerlink" title="获取系统当前时间"></a>获取系统当前时间</h3><p>这个就是获取当前时间即可，但是问题是，<strong>并发很高的时候</strong>，比如一秒并发几千，<strong>会有重复的情况</strong>，这个是肯定不合适的。基本就不用考虑了。</p><p>适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。</p><h3 id="snowflake-算法"><a href="#snowflake-算法" class="headerlink" title="snowflake 算法"></a>snowflake 算法</h3><p>snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。</p><ul><li>1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。</li><li>41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 <code>2^41 - 1</code>，也就是可以标识 <code>2^41 - 1</code> 个毫秒值，换算成年就是表示69年的时间。</li><li>10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 <code>2^5</code>个机房（32个机房），每个机房里可以代表 <code>2^5</code> 个机器（32台机器）。</li><li>12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 <code>2^12 - 1 = 4096</code>，也就是说可以用这个 12 bit 代表的数字来区分<strong>同一个毫秒内</strong>的 4096 个不同的 id。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000</div></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IdWorker</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerId;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterId;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequence;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IdWorker</span><span class="params">(<span class="keyword">long</span> workerId, <span class="keyword">long</span> datacenterId, <span class="keyword">long</span> sequence)</span> </span>&#123;</div><div class="line">        <span class="comment">// sanity check for workerId</span></div><div class="line">        <span class="comment">// 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0</span></div><div class="line">        <span class="keyword">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</div><div class="line">                    String.format(<span class="string">"worker Id can't be greater than %d or less than 0"</span>, maxWorkerId));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</div><div class="line">                    String.format(<span class="string">"datacenter Id can't be greater than %d or less than 0"</span>, maxDatacenterId));</div><div class="line">        &#125;</div><div class="line">        System.out.printf(</div><div class="line">                <span class="string">"worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d"</span>,</div><div class="line">                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);</div><div class="line"></div><div class="line">        <span class="keyword">this</span>.workerId = workerId;</div><div class="line">        <span class="keyword">this</span>.datacenterId = datacenterId;</div><div class="line">        <span class="keyword">this</span>.sequence = sequence;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> twepoch = <span class="number">1288834974657L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerIdBits = <span class="number">5L</span>;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdBits = <span class="number">5L</span>;</div><div class="line"></div><div class="line">    <span class="comment">// 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> maxWorkerId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; workerIdBits);</div><div class="line"></div><div class="line">    <span class="comment">// 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> maxDatacenterId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; datacenterIdBits);</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequenceBits = <span class="number">12L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerIdShift = sequenceBits;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdShift = sequenceBits + workerIdBits;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequenceMask = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; sequenceBits);</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> lastTimestamp = -<span class="number">1L</span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getWorkerId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> workerId;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getDatacenterId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> datacenterId;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getTimestamp</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> System.currentTimeMillis();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">// 这儿就是获取当前时间戳，单位是毫秒</span></div><div class="line">        <span class="keyword">long</span> timestamp = timeGen();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (timestamp &lt; lastTimestamp) &#123;</div><div class="line">            System.err.printf(<span class="string">"clock is moving backwards.  Rejecting requests until %d."</span>, lastTimestamp);</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(String.format(</div><div class="line">                    <span class="string">"Clock moved backwards.  Refusing to generate id for %d milliseconds"</span>, lastTimestamp - timestamp));</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (lastTimestamp == timestamp) &#123;</div><div class="line">            <span class="comment">// 这个意思是说一个毫秒内最多只能有4096个数字</span></div><div class="line">            <span class="comment">// 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围</span></div><div class="line">            sequence = (sequence + <span class="number">1</span>) &amp; sequenceMask;</div><div class="line">            <span class="keyword">if</span> (sequence == <span class="number">0</span>) &#123;</div><div class="line">                timestamp = tilNextMillis(lastTimestamp);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            sequence = <span class="number">0</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 这儿记录一下最近一次生成id的时间戳，单位是毫秒</span></div><div class="line">        lastTimestamp = timestamp;</div><div class="line"></div><div class="line">        <span class="comment">// 这儿就是将时间戳左移，放到 41 bit那儿；</span></div><div class="line">        <span class="comment">// 将机房 id左移放到 5 bit那儿；</span></div><div class="line">        <span class="comment">// 将机器id左移放到5 bit那儿；将序号放最后12 bit；</span></div><div class="line">        <span class="comment">// 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型</span></div><div class="line">        <span class="keyword">return</span> ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift)</div><div class="line">                | (workerId &lt;&lt; workerIdShift) | sequence;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">tilNextMillis</span><span class="params">(<span class="keyword">long</span> lastTimestamp)</span> </span>&#123;</div><div class="line">        <span class="keyword">long</span> timestamp = timeGen();</div><div class="line">        <span class="keyword">while</span> (timestamp &lt;= lastTimestamp) &#123;</div><div class="line">            timestamp = timeGen();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> timestamp;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">timeGen</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> System.currentTimeMillis();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// ---------------测试---------------</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        IdWorker worker = <span class="keyword">new</span> IdWorker(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">30</span>; i++) &#123;</div><div class="line">            System.out.println(worker.nextId());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个<strong>机房</strong> id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的<strong>机器</strong> id（但是最大只能是 32 以内），剩下的那个 12 bit序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。</p><p>所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。</p><p>利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。</p><p>这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;分库分表之后，id 主键如何处理？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个&lt;strong&gt;全局唯一&lt;/strong&gt;的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>如何设计可以动态扩容缩容的分库分表方案？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/25/%E9%9D%A2%E8%AF%95/2020-5-25-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%8F%AF%E4%BB%A5%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E7%BC%A9%E5%AE%B9%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/25/面试/2020-5-25-如何设计可以动态扩容缩容的分库分表方案？/</id>
    <published>2020-05-25T03:52:00.000Z</published>
    <updated>2020-05-29T03:03:24.022Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何设计可以动态扩容缩容的分库分表方案？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>对于分库分表来说，主要是面对以下问题：</p><ul><li>选择一个数据库中间件，调研、学习、测试；</li><li>设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；</li><li>基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；</li><li>完成单库单表到分库分表的<strong>迁移</strong>，双写方案；</li><li>线上系统开始基于分库分表对外提供服务；</li><li>扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？</li></ul><p>这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。</p><p>那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。</p><p>这都是玩儿分库分表线上必须经历的事儿。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/25/面试/2020-5-25-如何设计可以动态扩容缩容的分库分表方案？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/25/面试/2020-5-25-如何设计可以动态扩容缩容的分库分表方案？/'>如何设计可以动态扩容缩容的分库分表方案？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="停机扩容（不推荐）"><a href="#停机扩容（不推荐）" class="headerlink" title="停机扩容（不推荐）"></a>停机扩容（不推荐）</h3><p>这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然<strong>分库分表</strong>就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。</p><p>从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1小时数据就导完了。这没有问题。</p><p>如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。</p><h3 id="优化后的方案"><a href="#优化后的方案" class="headerlink" title="优化后的方案"></a>优化后的方案</h3><p>一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。</p><p>我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。</p><p>每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 <em> 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 </em> 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。</p><p>有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。</p><p>1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。</p><p>每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。</p><p>谈分库分表的扩容，<strong>第一次分库分表，就一次性给他分个够</strong>，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。</p><p>一个实践是利用 <code>32 * 32</code> 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。</p><table><thead><tr><th>orderId</th><th>id % 32 (库)</th><th>id / 32 % 32 (表)</th></tr></thead><tbody><tr><td>259</td><td>3</td><td>8</td></tr><tr><td>1189</td><td>5</td><td>5</td></tr><tr><td>352</td><td>0</td><td>11</td></tr><tr><td>4593</td><td>17</td><td>15</td></tr></tbody></table><p>刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 mysql 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 mysql 服务器之间做迁移就可以了。然后系统配合改一下配置即可。</p><p>比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。</p><p>这么搞，是不用自己写代码做数据迁移的，都交给 dba 来搞好了，但是 dba 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。</p><p>哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。</p><p>这里对步骤做一个总结：</p><ol><li>设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。</li><li>路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表</li><li>扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。</li><li>由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。</li><li>我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。</li><li>重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何设计可以动态扩容缩容的分库分表方案？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;对于分库分表来说，主要是面对以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选择一个数据库中间件，调研、学习、测试；&lt;/li&gt;
&lt;li&gt;设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；&lt;/li&gt;
&lt;li&gt;基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；&lt;/li&gt;
&lt;li&gt;完成单库单表到分库分表的&lt;strong&gt;迁移&lt;/strong&gt;，双写方案；&lt;/li&gt;
&lt;li&gt;线上系统开始基于分库分表对外提供服务；&lt;/li&gt;
&lt;li&gt;扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。&lt;/p&gt;
&lt;p&gt;那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。&lt;/p&gt;
&lt;p&gt;这都是玩儿分库分表线上必须经历的事儿。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>分库分表如何平滑过渡？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/24/%E9%9D%A2%E8%AF%95/2020-5-24-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%A6%82%E4%BD%95%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/24/面试/2020-5-24-分库分表如何平滑过渡？/</id>
    <published>2020-05-24T03:52:00.000Z</published>
    <updated>2020-05-29T03:01:55.918Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表<strong>动态切换</strong>到分库分表上？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？</p><p>所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/24/面试/2020-5-24-分库分表如何平滑过渡？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/24/面试/2020-5-24-分库分表如何平滑过渡？/'>分库分表如何平滑过渡？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。</p><h3 id="停机迁移方案"><a href="#停机迁移方案" class="headerlink" title="停机迁移方案"></a>停机迁移方案</h3><p>我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。</p><p>接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个<strong>导数的一次性工具</strong>，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。</p><p>导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。</p><p>验证一下，ok了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。</p><p>但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。</p><p><img src="https://i.loli.net/2020/05/28/VF8JKwYEfyu6H9v.png" alt="database-shard-method-1.png"></p><h3 id="双写迁移方案"><a href="#双写迁移方案" class="headerlink" title="双写迁移方案"></a>双写迁移方案</h3><p>这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。</p><p>简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，<strong>除了对老库增删改，都加上对新库的增删改</strong>，这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</p><p>然后<strong>系统部署</strong>之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。</p><p>导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。</p><p>接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。</p><p><img src="https://i.loli.net/2020/05/28/YkvqeFGnUxZPVyI.png" alt="database-shard-method-2.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表&lt;strong&gt;动态切换&lt;/strong&gt;到分库分表上？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？&lt;/p&gt;
&lt;p&gt;所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>为什么要分库分表？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/23/%E9%9D%A2%E8%AF%95/2020-5-23-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/23/面试/2020-5-23-为什么要分库分表？/</id>
    <published>2020-05-23T03:52:00.000Z</published>
    <updated>2020-05-29T03:00:14.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这块肯定是扯到<strong>高并发</strong>了，因为分库分表一定是为了<strong>支撑高并发、数据量大</strong>两个问题的。而且现在说实话，尤其是互联网类的公司面试，基本上都会来这么一下，分库分表如此普遍的技术问题，不问实在是不行，而如果你不知道那也实在是说不过去！</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/23/面试/2020-5-23-为什么要分库分表？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/23/面试/2020-5-23-为什么要分库分表？/'>为什么要分库分表？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"><a href="#为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）" class="headerlink" title="为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"></a>为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）</h3><p>说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。</p><p>我先给大家抛出来一个场景。</p><p>假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。我的天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。</p><p>结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！</p><p>好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢……</p><p>再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。</p><p>但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 <code>5000~8000</code>！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！</p><p>好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。</p><h4 id="分表"><a href="#分表" class="headerlink" title="分表"></a>分表</h4><p>比如你单表都几千万数据了，你确定你能扛住么？绝对不行，<strong>单表数据量太大</strong>，会极大影响你的 sql <strong>执行的性能</strong>，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p><p>分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p><h4 id="分库"><a href="#分库" class="headerlink" title="分库"></a>分库</h4><p>分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p><p>这就是所谓的<strong>分库分表</strong>，为啥要分库分表？你明白了吧。</p><table><thead><tr><th>#</th><th>分库分表前</th><th>分库分表后</th></tr></thead><tbody><tr><td>并发支撑情况</td><td>MySQL 单机部署，扛不住高并发</td><td>MySQL从单机到多机，能承受的并发增加了多倍</td></tr><tr><td>磁盘使用情况</td><td>MySQL 单机磁盘容量几乎撑满</td><td>拆分为多个库，数据库服务器磁盘使用率大大降低</td></tr><tr><td>SQL 执行性能</td><td>单表数据量太大，SQL 越跑越慢</td><td>单表数据量减少，SQL 执行效率明显提升</td></tr></tbody></table><h3 id="用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"><a href="#用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？" class="headerlink" title="用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"></a>用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</h3><p>这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。</p><p>比较常见的包括：</p><ul><li>Cobar</li><li>TDDL</li><li>Atlas</li><li>Sharding-jdbc</li><li>Mycat</li></ul><h4 id="Cobar"><a href="#Cobar" class="headerlink" title="Cobar"></a>Cobar</h4><p>阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p><h4 id="TDDL"><a href="#TDDL" class="headerlink" title="TDDL"></a>TDDL</h4><p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p><h4 id="Atlas"><a href="#Atlas" class="headerlink" title="Atlas"></a>Atlas</h4><p>360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p><h4 id="Sharding-jdbc"><a href="#Sharding-jdbc" class="headerlink" title="Sharding-jdbc"></a>Sharding-jdbc</h4><p>当当开源的，属于 client 层方案，是<a href="https://shardingsphere.apache.org" target="_blank" rel="external"><code>ShardingSphere</code></a>的 client 层方案，<a href="https://shardingsphere.apache.org" target="_blank" rel="external"><code>ShardingSphere</code></a>还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 <code>4.0.0-RC1</code> 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</p><h4 id="Mycat"><a href="#Mycat" class="headerlink" title="Mycat"></a>Mycat</h4><p>基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。</p><p>Sharding-jdbc 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> Sharding-jdbc 的依赖；</p><p>Mycat 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了。</p><p>通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。</p><h3 id="你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"><a href="#你们具体是如何对数据库如何进行垂直拆分或水平拆分的？" class="headerlink" title="你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"></a>你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</h3><p><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。</p><p><img src="https://i.loli.net/2020/05/23/9Y3I1foGaXieW4v.png" alt="database-split-horizon.png"></p><p><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p><p><img src="https://i.loli.net/2020/05/23/hXmae7uzn4wijyR.png" alt="database-split-vertically.png"></p><p>这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。</p><p>还有<strong>表层面的拆分</strong>，就是分表，将一个表变成 N 个表，就是<strong>让每个表的数据量控制在一定范围内</strong>，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。</p><p>好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，<strong>中间件可以根据你指定的某个字段值</strong>，比如说 userid，<strong>自动路由到对应的库上去，然后再自动路由到对应的表里去</strong>。</p><p>你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。</p><p>而且这儿还有两种<strong>分库分表的方式</strong>：</p><ul><li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li><li>或者是按照某个字段 hash 一下均匀分散，这个较为常用。</li></ul><p>range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</p><p>hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实这块肯定是扯到&lt;strong&gt;高并发&lt;/strong&gt;了，因为分库分表一定是为了&lt;strong&gt;支撑高并发、数据量大&lt;/strong&gt;两个问题的。而且现在说实话，尤其是互联网类的公司面试，基本上都会来这么一下，分库分表如此普遍的技术问题，不问实在是不行，而如果你不知道那也实在是说不过去！&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>生产环境中的Redis是怎么部署的？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/22/%E9%9D%A2%E8%AF%95/2020-5-22-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84Redis%E6%98%AF%E6%80%8E%E4%B9%88%E9%83%A8%E7%BD%B2%E7%9A%84%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/22/面试/2020-5-22-生产环境中的Redis是怎么部署的？/</id>
    <published>2020-05-22T03:52:00.000Z</published>
    <updated>2020-05-09T06:45:52.772Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>生产环境中的 redis 是怎么部署的？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>看看你了解不了解你们公司的 redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你的 redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确保可以进行数据恢复？线上 redis 给几个 G 的内存？设置了哪些参数？压测后你们 redis 集群承载多少 QPS？</p><p>兄弟，这些你必须是门儿清的，否则你确实是没好好思考过。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/22/面试/2020-5-22-生产环境中的Redis是怎么部署的？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/22/面试/2020-5-22-生产环境中的Redis是怎么部署的？/'>生产环境中的Redis是怎么部署的？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。</p><p>机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p><p>5 台机器对外提供读写，一共有 50g 内存。</p><p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p><p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p><p>其实大型的公司，会有基础架构的 team 负责缓存集群的运维。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;生产环境中的 redis 是怎么部署的？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;看看你了解不了解你们公司的 redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你的 redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确保可以进行数据恢复？线上 redis 给几个 G 的内存？设置了哪些参数？压测后你们 redis 集群承载多少 QPS？&lt;/p&gt;
&lt;p&gt;兄弟，这些你必须是门儿清的，否则你确实是没好好思考过。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>如何解决Redis的并发竞争问题？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/21/%E9%9D%A2%E8%AF%95/2020-5-21-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3Redis%E7%9A%84%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E9%97%AE%E9%A2%98%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/21/面试/2020-5-21-如何解决Redis的并发竞争问题？/</id>
    <published>2020-05-21T03:52:00.000Z</published>
    <updated>2020-05-09T06:44:36.277Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个也是线上非常常见的一个问题，就是<strong>多客户端同时并发写</strong>一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。</p><p>而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/21/面试/2020-5-21-如何解决Redis的并发竞争问题？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/21/面试/2020-5-21-如何解决Redis的并发竞争问题？/'>如何解决Redis的并发竞争问题？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。</p><p><img src="https://i.loli.net/2020/05/09/ZKFW4tc5nhJIb1D.png" alt="zookeeper-distributed-lock.png"></p><p>你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。</p><p>每次要<strong>写之前，先判断</strong>一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个也是线上非常常见的一个问题，就是&lt;strong&gt;多客户端同时并发写&lt;/strong&gt;一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。&lt;/p&gt;
&lt;p&gt;而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>如何保证缓存与数据库双写一致性？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/20/%E9%9D%A2%E8%AF%95/2020-5-20-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/20/面试/2020-5-20-如何保证缓存与数据库双写一致性？/</id>
    <published>2020-05-20T03:52:00.000Z</published>
    <updated>2020-05-09T06:43:21.713Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证缓存与数据库的双写一致性？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p><p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/20/面试/2020-5-20-如何保证缓存与数据库双写一致性？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/20/面试/2020-5-20-如何保证缓存与数据库双写一致性？/'>如何保证缓存与数据库双写一致性？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h3 id="Cache-Aside-Pattern"><a href="#Cache-Aside-Pattern" class="headerlink" title="Cache Aside Pattern"></a>Cache Aside Pattern</h3><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p><ul><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li></ul><p><strong>为什么是删除缓存，而不是更新缓存？</strong></p><p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p><p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p><p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p><p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p><p>其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p><h3 id="最初级的缓存不一致问题及解决方案"><a href="#最初级的缓存不一致问题及解决方案" class="headerlink" title="最初级的缓存不一致问题及解决方案"></a>最初级的缓存不一致问题及解决方案</h3><p>问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p><p><img src="https://i.loli.net/2020/05/09/eQzLxlaiW1HbSOu.png" alt="redis-junior-inconsistent.png"></p><p>解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p><h3 id="比较复杂的数据不一致问题分析"><a href="#比较复杂的数据不一致问题分析" class="headerlink" title="比较复杂的数据不一致问题分析"></a>比较复杂的数据不一致问题分析</h3><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了…</p><p><strong>为什么上亿流量高并发场景下，缓存会出现这个问题？</strong></p><p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就<strong>可能会出现上述的数据库+缓存不一致的情况</strong>。</p><p><strong>解决方案如下：</strong></p><p>更新数据的时候，根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。</p><p>一个队列对应一个工作线程，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p><p>这里有一个<strong>优化点</strong>，一个队列中，其实<strong>多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p><p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p><p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。</p><p>高并发的场景下，该解决方案要注意的问题：</p><ul><li>读请求长时阻塞</li></ul><p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。</p><p>该解决方案，最大的风险点在于说，<strong>可能数据更新很频繁</strong>，导致队列中积压了大量更新操作在里面，然后<strong>读请求会发生大量的超时</strong>，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。</p><p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要<strong>部署多个服务</strong>，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 <em> 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致<em>*读请求的长时阻塞</em></em>。</p><p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。</p><p><strong>如果一个内存队列中可能积压的更新操作特别多</strong>，那么你就要<strong>加机器</strong>，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。</p><p>其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。</p><p>我们来<strong>实际粗略测算一下</strong>。</p><p>如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。</p><p>经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。</p><ul><li>读请求并发量过高</li></ul><p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。</p><p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。</p><ul><li>多服务实例部署的请求路由</li></ul><p>可能这个服务部署了多个实例，那么必须<strong>保证</strong>说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器<strong>路由到相同的服务实例上</strong>。</p><p>比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。</p><ul><li>热点商品的路由问题，导致请求的倾斜</li></ul><p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何保证缓存与数据库的双写一致性？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？&lt;/p&gt;
&lt;h2 id=&quot;面试题剖析&quot;&gt;&lt;a href=&quot;#面试题剖析&quot; class=&quot;headerlink&quot; title=&quot;面试题剖析&quot;&gt;&lt;/a&gt;面试题剖析&lt;/h2&gt;&lt;p&gt;一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统&lt;strong&gt;不是严格要求&lt;/strong&gt; “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：&lt;strong&gt;读请求和写请求串行化&lt;/strong&gt;，串到一个&lt;strong&gt;内存队列&lt;/strong&gt;里去。&lt;/p&gt;
&lt;p&gt;串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis的雪崩、穿透和击穿，如何应对？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/19/%E9%9D%A2%E8%AF%95/2020-5-19-redis%E7%9A%84%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E5%92%8C%E5%87%BB%E7%A9%BF%EF%BC%8C%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/19/面试/2020-5-19-redis的雪崩、穿透和击穿，如何应对？/</id>
    <published>2020-05-19T03:52:00.000Z</published>
    <updated>2020-05-09T06:41:56.659Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/19/面试/2020-5-19-redis的雪崩、穿透和击穿，如何应对？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/19/面试/2020-5-19-redis的雪崩、穿透和击穿，如何应对？/'>redis的雪崩、穿透和击穿，如何应对？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p><p>这就是缓存雪崩。</p><p><img src="https://i.loli.net/2020/05/09/fdJ2wZzrlkbDHeL.png" alt="redis-caching-avalanche.png"></p><p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p><p>缓存雪崩的事前事中事后的解决方案如下：</p><ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><p><img src="https://i.loli.net/2020/05/09/hiZDFAvIx5JNMqm.png" alt="redis-caching-avalanche-solution.png"></p><p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。</p><p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空值。</p><p>好处：</p><ul><li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li><li>只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。</li><li>只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。</li></ul><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><p><img src="https://i.loli.net/2020/05/09/2Mvu5sJjlQOS6YK.png" alt="redis-caching-penetration.png"></p><p>解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</p><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><p>不同场景下的解决方式可如下：</p><ul><li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li><li>若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="消息队列" scheme="http://shenshanlaoyuan.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Redis集群模式的工作原理能说一下么？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/18/%E9%9D%A2%E8%AF%95/2020-5-18-Redis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E8%83%BD%E8%AF%B4%E4%B8%80%E4%B8%8B%E4%B9%88%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/18/面试/2020-5-18-Redis集群模式的工作原理能说一下么？/</id>
    <published>2020-05-18T03:52:00.000Z</published>
    <updated>2020-05-09T06:40:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得<strong>借助一些中间件</strong>来实现，比如说有 <code>codis</code>，或者 <code>twemproxy</code>，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。</p><p>这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。</p><p>现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。</p><p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。</p><p>redis cluster，主要是针对<strong>海量数据+高并发+高可用</strong>的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/18/面试/2020-5-18-Redis集群模式的工作原理能说一下么？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/18/面试/2020-5-18-Redis集群模式的工作原理能说一下么？/'>Redis集群模式的工作原理能说一下么？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-cluster-介绍"><a href="#redis-cluster-介绍" class="headerlink" title="redis cluster 介绍"></a>redis cluster 介绍</h3><ul><li>自动将数据进行分片，每个 master 上放一部分数据</li><li>提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的</li></ul><p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。</p><p>16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，<code>gossip</code> 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p><h3 id="节点间的内部通信机制"><a href="#节点间的内部通信机制" class="headerlink" title="节点间的内部通信机制"></a>节点间的内部通信机制</h3><h4 id="基本通信原理"><a href="#基本通信原理" class="headerlink" title="基本通信原理"></a>基本通信原理</h4><p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p><p><strong>集中式</strong>是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 <code>storm</code>。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><p><img src="https://i.loli.net/2020/05/09/tTmNvnj5HMQfuGq.png" alt="zookeeper-centralized-storage.png"></p><p>redis 维护集群元数据采用另一个方式， <code>gossip</code> 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><p><img src="https://i.loli.net/2020/05/09/KSLQupvrWTXxmoH.png" alt="redis-gossip.png"></p><p><strong>集中式</strong>的<strong>好处</strong>在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；<strong>不好</strong>在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</p><p>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p><ul><li><p>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 <code>ping</code> 消息，同时其它几个节点接收到 <code>ping</code> 之后返回 <code>pong</code>。</p></li><li><p>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</p></li></ul><h4 id="gossip-协议"><a href="#gossip-协议" class="headerlink" title="gossip 协议"></a>gossip 协议</h4><p>gossip 协议包含多种消息，包含 <code>ping</code>,<code>pong</code>,<code>meet</code>,<code>fail</code> 等等。</p><ul><li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">redis-trib.rb add-node</div></pre></td></tr></table></figure><p>其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。</p><ul><li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</li><li>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</li><li>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</li></ul><h4 id="ping-消息深入"><a href="#ping-消息深入" class="headerlink" title="ping 消息深入"></a>ping 消息深入</h4><p>ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。</p><p>每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 <code>cluster_node_timeout / 2</code>，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 <code>cluster_node_timeout</code> 可以调节，如果调得比较大，那么会降低 ping 的频率。</p><p>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 <code>3</code> 个其它节点的信息，最多包含 <code>总节点数减 2</code> 个其它节点的信息。</p><h3 id="分布式寻址算法"><a href="#分布式寻址算法" class="headerlink" title="分布式寻址算法"></a>分布式寻址算法</h3><ul><li>hash 算法（大量缓存重建）</li><li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li><li>redis cluster 的 hash slot 算法</li></ul><h4 id="hash-算法"><a href="#hash-算法" class="headerlink" title="hash 算法"></a>hash 算法</h4><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致<strong>大部分的请求过来，全部无法拿到有效的缓存</strong>，导致大量的流量涌入数据库。</p><p><img src="https://i.loli.net/2020/05/09/KQxa1OE79g2TNsY.png" alt="hash.png"></p><h4 id="一致性-hash-算法"><a href="#一致性-hash-算法" class="headerlink" title="一致性 hash 算法"></a>一致性 hash 算法</h4><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。</p><p><img src="https://i.loli.net/2020/05/09/Rz9WVuLSrmhsTwE.png" alt="consistent-hashing-algorithm.png"></p><h4 id="redis-cluster-的-hash-slot-算法"><a href="#redis-cluster-的-hash-slot-算法" class="headerlink" title="redis cluster 的 hash slot 算法"></a>redis cluster 的 hash slot 算法</h4><p>redis cluster 有固定的 <code>16384</code> 个 hash slot，对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 key 对应的 hash slot。</p><p>redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <code>hash tag</code> 来实现。</p><p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。</p><p><img src="https://i.loli.net/2020/05/09/FYQdlar4cBx5mPJ.png" alt="hash-slot.png"></p><h3 id="redis-cluster-的高可用与主备切换原理"><a href="#redis-cluster-的高可用与主备切换原理" class="headerlink" title="redis cluster 的高可用与主备切换原理"></a>redis cluster 的高可用与主备切换原理</h3><p>redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p><h4 id="判断节点宕机"><a href="#判断节点宕机" class="headerlink" title="判断节点宕机"></a>判断节点宕机</h4><p>如果一个节点认为另外一个节点宕机，那么就是 <code>pfail</code>，<strong>主观宕机</strong>。如果多个节点都认为另外一个节点宕机了，那么就是 <code>fail</code>，<strong>客观宕机</strong>，跟哨兵的原理几乎一样，sdown，odown。</p><p>在 <code>cluster-node-timeout</code> 内，某个节点一直没有返回 <code>pong</code>，那么就被认为 <code>pfail</code>。</p><p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中，<code>ping</code> 给其他节点，如果<strong>超过半数</strong>的节点都认为 <code>pfail</code> 了，那么就会变成 <code>fail</code>。</p><h4 id="从节点过滤"><a href="#从节点过滤" class="headerlink" title="从节点过滤"></a>从节点过滤</h4><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p><p>检查每个 slave node 与 master node 断开连接的时间，如果超过了 <code>cluster-node-timeout * cluster-slave-validity-factor</code>，那么就<strong>没有资格</strong>切换成 <code>master</code>。</p><h4 id="从节点选举"><a href="#从节点选举" class="headerlink" title="从节点选举"></a>从节点选举</h4><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p><p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node<code>（N/2 + 1）</code>都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p><p>从节点执行主备切换，从节点切换为主节点。</p><h4 id="与哨兵比较"><a href="#与哨兵比较" class="headerlink" title="与哨兵比较"></a>与哨兵比较</h4><p>整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得&lt;strong&gt;借助一些中间件&lt;/strong&gt;来实现，比如说有 &lt;code&gt;codis&lt;/code&gt;，或者 &lt;code&gt;twemproxy&lt;/code&gt;，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。&lt;/p&gt;
&lt;p&gt;这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。&lt;/p&gt;
&lt;p&gt;现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。&lt;/p&gt;
&lt;p&gt;如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。&lt;/p&gt;
&lt;p&gt;redis cluster，主要是针对&lt;strong&gt;海量数据+高并发+高可用&lt;/strong&gt;的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Redis的持久化有哪几种方式？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/16/%E9%9D%A2%E8%AF%95/2020-5-16-Redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/16/面试/2020-5-16-Redis的持久化有哪几种方式？/</id>
    <published>2020-05-16T03:52:00.000Z</published>
    <updated>2020-05-09T06:38:46.276Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>redis 如果仅仅只是将数据缓存在内存里面，如果 redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。</p><p>如果 redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。</p><p>这个其实一样，针对的都是 redis 的生产环境可能遇到的一些问题，就是 redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/16/面试/2020-5-16-Redis的持久化有哪几种方式？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/16/面试/2020-5-16-Redis的持久化有哪几种方式？/'>Redis的持久化有哪几种方式？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 redis 整个挂了，然后 redis 就不可用了，你要做的事情就是让 redis 变得可用，尽快变得可用。</p><p>重启 redis，尽快让它对外提供服务，如果没做数据备份，这时候 redis 启动了，也不可用啊，数据都没了。</p><p>很可能说，大量的请求过来，缓存全部无法命中，在 redis 里根本找不到数据，这个时候就死定了，出现<strong>缓存雪崩</strong>问题。所有请求没有在 redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql 承接高并发，然后就挂了…</p><p>如果你把 redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 redis 故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务。</p><h3 id="redis-持久化的两种方式"><a href="#redis-持久化的两种方式" class="headerlink" title="redis 持久化的两种方式"></a>redis 持久化的两种方式</h3><ul><li>RDB：RDB 持久化机制，是对 redis 中的数据执行<strong>周期性</strong>的持久化。</li><li>AOF：AOF 机制对每条写入命令作为日志，以 <code>append-only</code> 的模式写入一个日志文件中，在 redis 重启的时候，可以通过<strong>回放</strong> AOF 日志中的写入指令来重新构建整个数据集。</li></ul><p>通过 RDB 或 AOF，都可以将 redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。</p><p>如果 redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 redis，redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。</p><p>如果同时使用 RDB 和 AOF 两种持久化机制，那么在 redis 重启的时候，会使用 <strong>AOF</strong> 来重新构建数据，因为 AOF 中的<strong>数据更加完整</strong>。</p><h4 id="RDB-优缺点"><a href="#RDB-优缺点" class="headerlink" title="RDB 优缺点"></a>RDB 优缺点</h4><ul><li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，<strong>非常适合做冷备</strong>，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 redis 中的数据。</li><li>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis <strong>保持高性能</strong>，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li><li><p>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。</p></li><li><p>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</p></li><li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li></ul><h4 id="AOF-优缺点"><a href="#AOF-优缺点" class="headerlink" title="AOF 优缺点"></a>AOF 优缺点</h4><ul><li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次<code>fsync</code>操作，最多丢失 1 秒钟的数据。</li><li>AOF 日志文件以 <code>append-only</code> 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li><li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 <code>rewrite</code> log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li><li>AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常<strong>适合做灾难性的误删除的紧急恢复</strong>。比如某人不小心用 <code>flushall</code> 命令清空了所有数据，只要这个时候后台 <code>rewrite</code> 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 <code>flushall</code> 命令给删了，然后再将该 <code>AOF</code> 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li><li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li><li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 <code>fsync</code> 一次日志文件，当然，每秒一次 <code>fsync</code>，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低）</li><li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是<strong>基于当时内存中的数据进行指令的重新构建</strong>，这样健壮性会好很多。</li></ul><h3 id="RDB-和-AOF-到底该如何选择"><a href="#RDB-和-AOF-到底该如何选择" class="headerlink" title="RDB 和 AOF 到底该如何选择"></a>RDB 和 AOF 到底该如何选择</h3><ul><li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</li><li>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</li><li>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;redis 如果仅仅只是将数据缓存在内存里面，如果 redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。&lt;/p&gt;
&lt;p&gt;如果 redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。&lt;/p&gt;
&lt;p&gt;这个其实一样，针对的都是 redis 的生产环境可能遇到的一些问题，就是 redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>如何保证Redis高并发、高可用？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/15/%E9%9D%A2%E8%AF%95/2020-5-15-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81Redis%E9%AB%98%E5%B9%B6%E5%8F%91%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/15/面试/2020-5-15-如何保证Redis高并发、高可用？/</id>
    <published>2020-05-15T03:52:00.000Z</published>
    <updated>2020-05-09T06:37:20.643Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实问这个问题，主要是考考你，redis 单机能承载多高并发？如果单机扛不住如何扩容扛更多的并发？redis 会不会挂？既然 redis 会挂那怎么保证 redis 是高可用的？</p><p>其实针对的都是项目中你肯定要考虑的一些问题，如果你没考虑过，那确实你对生产系统中的问题思考太少。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/15/面试/2020-5-15-如何保证Redis高并发、高可用？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/15/面试/2020-5-15-如何保证Redis高并发、高可用？/'>如何保证Redis高并发、高可用？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>如果你用 redis 缓存技术的话，肯定要考虑如何用 redis 来加多台机器，保证 redis 是高并发的，还有就是如何让 redis 保证自己不是挂掉以后就直接死掉了，即 redis 高可用。</p><p>由于此节内容较多，因此，会分为两个小节进行讲解。</p><ul><li><a href="/docs/high-concurrency/redis-master-slave.md">redis 主从架构</a></li><li><a href="/docs/high-concurrency/redis-sentinel.md">redis 基于哨兵实现高可用</a></li></ul><p>redis 实现<strong>高并发</strong>主要依靠<strong>主从架构</strong>，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10w 的 QPS。</p><p>如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。</p><p>redis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实问这个问题，主要是考考你，redis 单机能承载多高并发？如果单机扛不住如何扩容扛更多的并发？redis 会不会挂？既然 redis 会挂那怎么保证 redis 是高可用的？&lt;/p&gt;
&lt;p&gt;其实针对的都是项目中你肯定要考虑的一些问题，如果你没考虑过，那确实你对生产系统中的问题思考太少。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Redis的过期策略都有哪些？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/13/%E9%9D%A2%E8%AF%95/2020-5-13-Redis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/13/面试/2020-5-13-Redis的过期策略都有哪些？/</id>
    <published>2020-05-13T03:52:00.000Z</published>
    <updated>2020-05-09T06:29:57.495Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？</p><p>常见的有两个问题：</p><ul><li>往 redis 写入的数据怎么没了？</li></ul><p>可能有同学会遇到，在生产环境的 redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 redis 你就没用对啊。redis 是缓存，你给当存储了是吧？</p><p>啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。redis 主要是基于内存来进行高性能、高并发的读写操作的。</p><p>那既然内存是有限的，比如 redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。</p><ul><li>数据明明过期了，怎么还占用着内存？</li></ul><p>这是由 redis 的过期策略来决定。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/13/面试/2020-5-13-Redis的过期策略都有哪些？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/13/面试/2020-5-13-Redis的过期策略都有哪些？/'>Redis的过期策略都有哪些？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-过期策略"><a href="#redis-过期策略" class="headerlink" title="redis 过期策略"></a>redis 过期策略</h3><p>redis 过期策略是：<strong>定期删除+惰性删除</strong>。</p><p>所谓<strong>定期删除</strong>，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。</p><p>假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的<strong>灾难</strong>。实际上 redis 是每隔 100ms <strong>随机抽取</strong>一些 key 来检查和删除的。</p><p>但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。</p><blockquote><p>获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。</p></blockquote><p>但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？</p><p>答案是：<strong>走内存淘汰机制</strong>。</p><h3 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h3><p>redis 内存淘汰机制有以下几个：</p><ul><li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li><li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li><li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li><li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li><li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li></ul><h3 id="手写一个-LRU-算法"><a href="#手写一个-LRU-算法" class="headerlink" title="手写一个 LRU 算法"></a>手写一个 LRU 算法</h3><p>你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。</p><p>不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> CACHE_SIZE;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 传递进来最多能缓存多少数据</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> cacheSize 缓存大小</div><div class="line">     */</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> cacheSize)</span> </span>&#123;</div><div class="line">        <span class="comment">// true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。</span></div><div class="line">        <span class="keyword">super</span>((<span class="keyword">int</span>) Math.ceil(cacheSize / <span class="number">0.75</span>) + <span class="number">1</span>, <span class="number">0.75f</span>, <span class="keyword">true</span>);</div><div class="line">        CACHE_SIZE = cacheSize;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 钩子方法，通过put新增键值对的时候，若该方法返回true</div><div class="line">     * 便移除该map中最老的键和值</div><div class="line">     */</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;K, V&gt; eldest)</span> </span>&#123;</div><div class="line">        <span class="comment">// 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。</span></div><div class="line">        <span class="keyword">return</span> size() &gt; CACHE_SIZE;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？&lt;/p&gt;
&lt;p&gt;常见的有两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;往 redis 写入的数据怎么没了？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可能有同学会遇到，在生产环境的 redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 redis 你就没用对啊。redis 是缓存，你给当存储了是吧？&lt;/p&gt;
&lt;p&gt;啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。redis 主要是基于内存来进行高性能、高并发的读写操作的。&lt;/p&gt;
&lt;p&gt;那既然内存是有限的，比如 redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据明明过期了，怎么还占用着内存？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这是由 redis 的过期策略来决定。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Redis都有哪些数据类型以及适用场景？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/12/%E9%9D%A2%E8%AF%95/2020-5-12-Redis%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%BB%A5%E5%8F%8A%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/12/面试/2020-5-12-Redis都有哪些数据类型以及适用场景？/</id>
    <published>2020-05-12T03:52:00.000Z</published>
    <updated>2020-05-09T06:28:35.986Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 都有哪些数据类型？分别在哪些场景下使用比较合适？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。</p><p>其实问这个问题，主要有两个原因：</p><ul><li>看看你到底有没有全面的了解 redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；</li><li>看看你在实际项目里都怎么玩儿过 redis。</li></ul><p>要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/12/面试/2020-5-12-Redis都有哪些数据类型以及适用场景？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/12/面试/2020-5-12-Redis都有哪些数据类型以及适用场景？/'>Redis都有哪些数据类型以及适用场景？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>redis 主要有以下几种数据类型：</p><ul><li>string</li><li>hash</li><li>list</li><li>set</li><li>sorted set</li></ul><h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> college szu</div></pre></td></tr></table></figure></p><h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p>这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的<strong>某个字段</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hset person name bingo</div><div class="line">hset person age 20</div><div class="line">hset person id 1</div><div class="line">hget person name</div></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">person = &#123;</div><div class="line">    "name": "bingo",</div><div class="line">    "age": 20,</div><div class="line">    "id": 1</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list 是有序列表，这个可以玩儿出很多花样。</p><p>比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p><p>比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。</span></div><div class="line">lrange mylist 0 -1</div></pre></td></tr></table></figure></p><p>比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">lpush mylist 1</div><div class="line">lpush mylist 2</div><div class="line">lpush mylist 3 4 5</div><div class="line"></div><div class="line"><span class="comment"># 1</span></div><div class="line">rpop mylist</div></pre></td></tr></table></figure></p><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set 是无序集合，自动去重。</p><p>直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。</p><p>可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</p><p>把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#-------操作一个set-------</span></div><div class="line"><span class="comment"># 添加元素</span></div><div class="line">sadd mySet 1</div><div class="line"></div><div class="line"><span class="comment"># 查看全部元素</span></div><div class="line">smembers mySet</div><div class="line"></div><div class="line"><span class="comment"># 判断是否包含某个值</span></div><div class="line">sismember mySet 3</div><div class="line"></div><div class="line"><span class="comment"># 删除某个/些元素</span></div><div class="line">srem mySet 1</div><div class="line">srem mySet 2 4</div><div class="line"></div><div class="line"><span class="comment"># 查看元素个数</span></div><div class="line">scard mySet</div><div class="line"></div><div class="line"><span class="comment"># 随机删除一个元素</span></div><div class="line">spop mySet</div><div class="line"></div><div class="line"><span class="comment">#-------操作多个set-------</span></div><div class="line"><span class="comment"># 将一个set的元素移动到另外一个set</span></div><div class="line">smove yourSet mySet 2</div><div class="line"></div><div class="line"><span class="comment"># 求两set的交集</span></div><div class="line">sinter yourSet mySet</div><div class="line"></div><div class="line"><span class="comment"># 求两set的并集</span></div><div class="line">sunion yourSet mySet</div><div class="line"></div><div class="line"><span class="comment"># 求在yourSet中而不在mySet中的元素</span></div><div class="line">sdiff yourSet mySet</div></pre></td></tr></table></figure></p><h3 id="sorted-set"><a href="#sorted-set" class="headerlink" title="sorted set"></a>sorted set</h3><p>sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">zadd board 85 zhangsan</div><div class="line">zadd board 72 lisi</div><div class="line">zadd board 96 wangwu</div><div class="line">zadd board 63 zhaoliu</div><div class="line"></div><div class="line"><span class="comment"># 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）</span></div><div class="line">zrevrange board 0 3</div><div class="line"></div><div class="line"><span class="comment"># 获取某用户的排名</span></div><div class="line">zrank board zhaoliu</div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 都有哪些数据类型？分别在哪些场景下使用比较合适？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。&lt;/p&gt;
&lt;p&gt;其实问这个问题，主要有两个原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;看看你到底有没有全面的了解 redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；&lt;/li&gt;
&lt;li&gt;看看你在实际项目里都怎么玩儿过 redis。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Redis和Memcached有什么区别？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/11/%E9%9D%A2%E8%AF%95/2020-5-11-Redis%E5%92%8CMemcached%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/11/面试/2020-5-11-Redis和Memcached有什么区别？/</id>
    <published>2020-05-11T03:52:00.000Z</published>
    <updated>2020-05-09T06:27:04.584Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 和 memcached 有什么区别？redis 的线程模型是什么？为什么 redis 单线程却能支撑高并发？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个是问 redis 的时候，最基本的问题吧，redis 最基本的一个内部原理和特点，就是 redis 实际上是个<strong>单线程工作模型</strong>，你要是这个都不知道，那后面玩儿 redis 的时候，出了问题岂不是什么都不知道？</p><p>还有可能面试官会问问你 redis 和 memcached 的区别，但是 memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 redis，没什么公司用 memcached 了。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/11/面试/2020-5-11-Redis和Memcached有什么区别？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/11/面试/2020-5-11-Redis和Memcached有什么区别？/'>Redis和Memcached有什么区别？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-和-memcached-有啥区别？"><a href="#redis-和-memcached-有啥区别？" class="headerlink" title="redis 和 memcached 有啥区别？"></a>redis 和 memcached 有啥区别？</h3><h4 id="redis-支持复杂的数据结构"><a href="#redis-支持复杂的数据结构" class="headerlink" title="redis 支持复杂的数据结构"></a>redis 支持复杂的数据结构</h4><p>redis 相比 memcached 来说，拥有<a href="/docs/high-concurrency/redis-data-types.md">更多的数据结构</a>，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。</p><h4 id="redis-原生支持集群模式"><a href="#redis-原生支持集群模式" class="headerlink" title="redis 原生支持集群模式"></a>redis 原生支持集群模式</h4><p>在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p><h4 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h4><p>由于 redis 只使用<strong>单核</strong>，而 memcached 可以使用<strong>多核</strong>，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。</p><h3 id="redis-的线程模型"><a href="#redis-的线程模型" class="headerlink" title="redis 的线程模型"></a>redis 的线程模型</h3><p>redis 内部使用文件事件处理器 <code>file event handler</code>，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p><p>来看客户端与 redis 的一次通信过程：</p><p><img src="https://i.loli.net/2020/05/09/DEkaYgBwlC7Qjds.png" alt="redis-single-thread-model.png"></p><p>要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。</p><p>首先，redis 服务端进程初始化的时候，会将 server socket 的 <code>AE_READABLE</code> 事件与连接应答处理器关联。</p><p>客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 <code>AE_READABLE</code> 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给<strong>连接应答处理器</strong>。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</p><p>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 redis 中的 socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 <code>AE_READABLE</code> 事件，由于前面 socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 <code>key value</code> 并在自己内存中完成 <code>key value</code> 的设置。操作完成后，它会将 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器关联。</p><p>如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code>，之后解除 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</p><p>这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《<a href="https://github.com/doocs/technical-books#database" target="_blank" rel="external">Redis 设计与实现——黄健宏</a>》进行系统学习。</p><h3 id="为啥-redis-单线程模型也能效率这么高？"><a href="#为啥-redis-单线程模型也能效率这么高？" class="headerlink" title="为啥 redis 单线程模型也能效率这么高？"></a>为啥 redis 单线程模型也能效率这么高？</h3><ul><li>纯内存操作。</li><li>核心是基于非阻塞的 IO 多路复用机制。</li><li>C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li><li>单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 和 memcached 有什么区别？redis 的线程模型是什么？为什么 redis 单线程却能支撑高并发？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个是问 redis 的时候，最基本的问题吧，redis 最基本的一个内部原理和特点，就是 redis 实际上是个&lt;strong&gt;单线程工作模型&lt;/strong&gt;，你要是这个都不知道，那后面玩儿 redis 的时候，出了问题岂不是什么都不知道？&lt;/p&gt;
&lt;p&gt;还有可能面试官会问问你 redis 和 memcached 的区别，但是 memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 redis，没什么公司用 memcached 了。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>在项目中缓存是如何使用的？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/10/%E9%9D%A2%E8%AF%95/2020-5-10-%E5%9C%A8%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%BC%93%E5%AD%98%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E7%9A%84%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/10/面试/2020-5-10-在项目中缓存是如何使用的？/</id>
    <published>2020-05-10T03:52:00.000Z</published>
    <updated>2020-05-09T06:24:56.006Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个问题，互联网公司必问，要是一个人连缓存都不太清楚，那确实比较尴尬。</p><p>只要问到缓存，上来第一个问题，肯定是先问问你项目哪里用了缓存？为啥要用？不用行不行？如果用了以后可能会有什么不良的后果？</p><p>这就是看看你对缓存这个东西背后有没有思考，如果你就是傻乎乎的瞎用，没法给面试官一个合理的解答，那面试官对你印象肯定不太好，觉得你平时思考太少，就知道干活儿。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/10/面试/2020-5-10-在项目中缓存是如何使用的？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/10/面试/2020-5-10-在项目中缓存是如何使用的？/'>在项目中缓存是如何使用的？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="项目中缓存是如何使用的？"><a href="#项目中缓存是如何使用的？" class="headerlink" title="项目中缓存是如何使用的？"></a>项目中缓存是如何使用的？</h3><p>这个，需要结合自己项目的业务来。</p><h3 id="为什么要用缓存？"><a href="#为什么要用缓存？" class="headerlink" title="为什么要用缓存？"></a>为什么要用缓存？</h3><p>用缓存，主要有两个用途：<strong>高性能</strong>、<strong>高并发</strong>。</p><h4 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h4><p>假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？</p><p>缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。</p><p>就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。</p><h4 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h4><p>mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 <code>2000QPS</code> 也开始容易报警了。</p><p>所以要是你有个系统，高峰期一秒钟过来的请求有 1万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 <code>key-value</code> 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。</p><blockquote><p>缓存是走内存的，内存天然就支撑高并发。</p></blockquote><h3 id="用了缓存之后会有什么不良后果？"><a href="#用了缓存之后会有什么不良后果？" class="headerlink" title="用了缓存之后会有什么不良后果？"></a>用了缓存之后会有什么不良后果？</h3><p>常见的缓存问题有以下几个：</p><ul><li><a href="/docs/high-concurrency/redis-consistence.md">缓存与数据库双写不一致</a></li><li><a href="/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md">缓存雪崩、缓存穿透、缓存击穿</a></li><li><a href="/docs/high-concurrency/redis-cas.md">缓存并发竞争</a></li></ul><p>点击超链接，可直接查看缓存相关问题及解决方案。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个问题，互联网公司必问，要是一个人连缓存都不太清楚，那确实比较尴尬。&lt;/p&gt;
&lt;p&gt;只要问到缓存，上来第一个问题，肯定是先问问你项目哪里用了缓存？为啥要用？不用行不行？如果用了以后可能会有什么不良的后果？&lt;/p&gt;
&lt;p&gt;这就是看看你对缓存这个东西背后有没有思考，如果你就是傻乎乎的瞎用，没法给面试官一个合理的解答，那面试官对你印象肯定不太好，觉得你平时思考太少，就知道干活儿。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>es生产集群的部署架构是什么？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/09/%E9%9D%A2%E8%AF%95/2020-5-9-es%E7%94%9F%E4%BA%A7%E9%9B%86%E7%BE%A4%E7%9A%84%E9%83%A8%E7%BD%B2%E6%9E%B6%E6%9E%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/09/面试/2020-5-9-es生产集群的部署架构是什么？/</id>
    <published>2020-05-09T03:52:00.000Z</published>
    <updated>2020-05-09T03:31:03.971Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>es 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个问题，包括后面的 redis 什么的，谈到 es、redis、mysql 分库分表等等技术，面试必问！就是你生产环境咋部署的？说白了，这个问题没啥技术含量，就是看你有没有在真正的生产环境里干过这事儿！</p><p>有些同学可能是没在生产环境中干过的，没实际去拿线上机器部署过 es 集群，也没实际玩儿过，也没往 es 集群里面导入过几千万甚至是几亿的数据量，可能你就不太清楚这里面的一些生产项目中的细节。</p><p>如果你是自己就玩儿过 demo，没碰过真实的 es 集群，那你可能此时会懵。别懵，你一定要云淡风轻的回答出来这个问题，表示你确实干过这事儿。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/09/面试/2020-5-9-es生产集群的部署架构是什么？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/09/面试/2020-5-9-es生产集群的部署架构是什么？/'>es生产集群的部署架构是什么？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实这个问题没啥，如果你确实干过 es，那你肯定了解你们生产 es 集群的实际情况，部署了几台机器？有多少个索引？每个索引有多大数据量？每个索引给了多少个分片？你肯定知道！</p><p>但是如果你确实没干过，也别虚，我给你说一个基本的版本，你到时候就简单说一下就好了。</p><ul><li>es 生产集群我们部署了 5 台机器，每台机器是 6 核 64G 的，集群总内存是 320G。</li><li>我们 es 集群的日增量数据大概是 2000 万条，每天日增量数据大概是 500MB，每月增量数据大概是 6 亿，15G。目前系统已经运行了几个月，现在 es 集群里数据总量大概是 100G 左右。</li><li>目前线上有 5 个索引（这个结合你们自己业务来，看看自己有哪些数据可以放 es 的），每个索引的数据量大概是 20G，所以这个数据量之内，我们每个索引分配的是 8 个 shard，比默认的 5 个 shard 多了 3 个 shard。</li></ul><p>大概就这么说一下就行了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;es 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个问题，包括后面的 redis 什么的，谈到 es、redis、mysql 分库分表等等技术，面试必问！就是你生产环境咋部署的？说白了，这个问题没啥技术含量，就是看你有没有在真正的生产环境里干过这事儿！&lt;/p&gt;
&lt;p&gt;有些同学可能是没在生产环境中干过的，没实际去拿线上机器部署过 es 集群，也没实际玩儿过，也没往 es 集群里面导入过几千万甚至是几亿的数据量，可能你就不太清楚这里面的一些生产项目中的细节。&lt;/p&gt;
&lt;p&gt;如果你是自己就玩儿过 demo，没碰过真实的 es 集群，那你可能此时会懵。别懵，你一定要云淡风轻的回答出来这个问题，表示你确实干过这事儿。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="搜索引擎" scheme="http://shenshanlaoyuan.com/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>es在数十亿级别数量下如何提高查询效率？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/08/%E9%9D%A2%E8%AF%95/2020-5-8-es%E5%9C%A8%E6%95%B0%E5%8D%81%E4%BA%BF%E7%BA%A7%E5%88%AB%E6%95%B0%E9%87%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E6%9F%A5%E8%AF%A2%E6%95%88%E7%8E%87%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/08/面试/2020-5-8-es在数十亿级别数量下如何提高查询效率？/</id>
    <published>2020-05-08T03:52:00.000Z</published>
    <updated>2020-05-09T03:29:30.802Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>es 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个问题是肯定要问的，说白了，就是看你有没有实际干过 es，因为啥？其实 es 性能并没有你想象中那么好的。很多时候数据量大了，特别是有几亿条数据的时候，可能你会懵逼的发现，跑个搜索怎么一下 <code>5~10s</code>，坑爹了。第一次搜索的时候，是  <code>5~10s</code>，后面反而就快了，可能就几百毫秒。</p><p>你就很懵，每个用户第一次访问都会比较慢，比较卡么？所以你要是没玩儿过 es，或者就是自己玩玩儿 demo，被问到这个问题容易懵逼，显示出你对 es 确实玩儿的不怎么样？</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/08/面试/2020-5-8-es在数十亿级别数量下如何提高查询效率？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/08/面试/2020-5-8-es在数十亿级别数量下如何提高查询效率？/'>es在数十亿级别数量下如何提高查询效率？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>说实话，es 性能优化是没有什么银弹的，啥意思呢？就是<strong>不要期待着随手调一个参数，就可以万能的应对所有的性能慢的场景</strong>。也许有的场景是你换个参数，或者调整一下语法，就可以搞定，但是绝对不是所有场景都可以这样。</p><h3 id="性能优化的杀手锏——filesystem-cache"><a href="#性能优化的杀手锏——filesystem-cache" class="headerlink" title="性能优化的杀手锏——filesystem cache"></a>性能优化的杀手锏——filesystem cache</h3><p>你往 es 里写的数据，实际上都写到磁盘文件里去了，<strong>查询的时候</strong>，操作系统会将磁盘文件里的数据自动缓存到 <code>filesystem cache</code> 里面去。</p><p><img src="https://i.loli.net/2020/05/08/RcFSKDZ3BmpA2q4.png" alt="es-search-process.png"></p><p>es 的搜索引擎严重依赖于底层的 <code>filesystem cache</code>，你如果给 <code>filesystem cache</code> 更多的内存，尽量让内存可以容纳所有的 <code>idx segment file</code> 索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。</p><p>性能差距究竟可以有多大？我们之前很多的测试和压测，如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒、5秒、10秒。但如果是走 <code>filesystem cache</code>，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。</p><p>这里有个真实的案例。某个公司 es 节点有 3 台机器，每台机器看起来内存很多，64G，总内存就是 <code>64 * 3 = 192G</code>。每台机器给 es jvm heap 是 <code>32G</code>，那么剩下来留给 <code>filesystem cache</code> 的就是每台机器才 <code>32G</code>，总共集群里给 <code>filesystem cache</code> 的就是 <code>32 * 3 = 96G</code> 内存。而此时，整个磁盘上索引数据文件，在 3 台机器上一共占用了 <code>1T</code> 的磁盘容量，es 数据量是 <code>1T</code>，那么每台机器的数据量是 <code>300G</code>。这样性能好吗？ <code>filesystem cache</code> 的内存才 100G，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差。</p><p>归根结底，你要让 es 性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半。</p><p>根据我们自己的生产环境实践经验，最佳的情况下，是仅仅在 es 中就存少量的数据，就是你要<strong>用来搜索的那些索引</strong>，如果内存留给 <code>filesystem cache</code> 的是 100G，那么你就将索引数据控制在 <code>100G</code> 以内，这样的话，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在 1 秒以内。</p><p>比如说你现在有一行数据。<code>id,name,age ....</code> 30 个字段。但是你现在搜索，只需要根据 <code>id,name,age</code> 三个字段来搜索。如果你傻乎乎往 es 里写入一行数据所有的字段，就会导致说 <code>90%</code> 的数据是不用来搜索的，结果硬是占据了 es 机器上的 <code>filesystem cache</code> 的空间，单条数据的数据量越大，就会导致 <code>filesystem cahce</code> 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的<strong>少数几个字段</strong>就可以了，比如说就写入 es <code>id,name,age</code> 三个字段，然后你可以把其他的字段数据存在 mysql/hbase 里，我们一般是建议用 <code>es + hbase</code> 这么一个架构。</p><p>hbase 的特点是<strong>适用于海量数据的在线存储</strong>，就是对 hbase 可以写入海量数据，但是不要做复杂的搜索，做很简单的一些根据 id 或者范围进行查询的这么一个操作就可以了。从 es 中根据 name 和 age 去搜索，拿到的结果可能就 20 个 <code>doc id</code>，然后根据 <code>doc id</code> 到 hbase 里去查询每个 <code>doc id</code> 对应的<strong>完整的数据</strong>，给查出来，再返回给前端。</p><p>写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms，可能你原来那么玩儿，1T 数据都放 es，会每次查询都是 5~10s，现在可能性能就会很高，每次查询就是 50ms。</p><h3 id="数据预热"><a href="#数据预热" class="headerlink" title="数据预热"></a>数据预热</h3><p>假如说，哪怕是你就按照上述的方案去做了，es 集群中每个机器写入的数据量还是超过了 <code>filesystem cache</code> 一倍，比如说你写入一台机器 60G 数据，结果 <code>filesystem cache</code> 就 30G，还是有 30G 数据留在了磁盘上。</p><p>其实可以做<strong>数据预热</strong>。</p><p>举个例子，拿微博来说，你可以把一些大V，平时看的人很多的数据，你自己提前后台搞个系统，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 <code>filesystem cache</code> 里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。</p><p>或者是电商，你可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 <code>filesystem cache</code> 里去。</p><p>对于那些你觉得比较热的、经常会有人访问的数据，最好<strong>做一个专门的缓存预热子系统</strong>，就是对热数据每隔一段时间，就提前访问一下，让数据进入 <code>filesystem cache</code> 里面去。这样下次别人访问的时候，性能一定会好很多。</p><h3 id="冷热分离"><a href="#冷热分离" class="headerlink" title="冷热分离"></a>冷热分离</h3><p>es 可以做类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将<strong>冷数据写入一个索引中，然后热数据写入另外一个索引中</strong>，这样可以确保热数据在被预热之后，尽量都让他们留在 <code>filesystem os cache</code> 里，<strong>别让冷数据给冲刷掉</strong>。</p><p>你看，假设你有 6 台机器，2 个索引，一个放冷数据，一个放热数据，每个索引 3 个 shard。3 台机器放热数据 index，另外 3 台机器放冷数据 index。然后这样的话，你大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 <code>filesystem cache</code> 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据，也无所谓了。</p><h3 id="document-模型设计"><a href="#document-模型设计" class="headerlink" title="document 模型设计"></a>document 模型设计</h3><p>对于 MySQL，我们经常有一些复杂的关联查询。在 es 里该怎么玩儿，es 里面的复杂的关联查询尽量别用，一旦用了性能一般都不太好。</p><p>最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 es 中。搜索的时候，就不需要利用 es 的搜索语法来完成 join 之类的关联搜索了。</p><p>document 模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es 能支持的操作就那么多，不要考虑用 es 做一些它不好操作的事情。如果真的有那种操作，尽量在 document 模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如 join/nested/parent-child 搜索都要尽量避免，性能都很差的。</p><h3 id="分页性能优化"><a href="#分页性能优化" class="headerlink" title="分页性能优化"></a>分页性能优化</h3><p>es 的分页是较坑的，为啥呢？举个例子吧，假如你每页是 10 条数据，你现在要查询第 100 页，实际上是会把每个 shard 上存储的前 1000 条数据都查到一个协调节点上，如果你有个 5 个 shard，那么就有 5000 条数据，接着协调节点对这 5000 条数据进行一些合并、处理，再获取到最终第 100 页的 10 条数据。</p><p>分布式的，你要查第 100 页的 10 条数据，不可能说从 5 个 shard，每个 shard 就查 2 条数据，最后到协调节点合并成 10 条数据吧？你<strong>必须</strong>得从每个 shard 都查 1000 条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第 100 页的数据。你翻页的时候，翻的越深，每个 shard 返回的数据就越多，而且协调节点处理的时间越长，非常坑爹。所以用 es 做分页的时候，你会发现越翻到后面，就越是慢。</p><p>我们之前也是遇到过这个问题，用 es 作分页，前几页就几十毫秒，翻到 10 页或者几十页的时候，基本上就要 5~10 秒才能查出来一页数据了。</p><p>有什么解决方案吗？</p><h4 id="不允许深度分页（默认深度分页性能很差）"><a href="#不允许深度分页（默认深度分页性能很差）" class="headerlink" title="不允许深度分页（默认深度分页性能很差）"></a>不允许深度分页（默认深度分页性能很差）</h4><p>跟产品经理说，你系统不允许翻那么深的页，默认翻的越深，性能就越差。</p><h4 id="类似于-app-里的推荐商品不断下拉出来一页一页的"><a href="#类似于-app-里的推荐商品不断下拉出来一页一页的" class="headerlink" title="类似于 app 里的推荐商品不断下拉出来一页一页的"></a>类似于 app 里的推荐商品不断下拉出来一页一页的</h4><p>类似于微博中，下拉刷微博，刷出来一页一页的，你可以用 <code>scroll api</code>，关于如何使用，自行上网搜索。</p><p>scroll 会一次性给你生成<strong>所有数据的一个快照</strong>，然后每次滑动向后翻页就是通过<strong>游标</strong> <code>scroll_id</code> 移动，获取下一页下一页这样子，性能会比上面说的那种分页性能要高很多很多，基本上都是毫秒级的。</p><p>但是，唯一的一点就是，这个适合于那种类似微博下拉翻页的，<strong>不能随意跳到任何一页的场景</strong>。也就是说，你不能先进入第 10 页，然后去第 120 页，然后又回到第 58 页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻。</p><p>初始化时必须指定 <code>scroll</code> 参数，告诉 es 要保存此次搜索的上下文多长时间。你需要确保用户不会持续不断翻页翻几个小时，否则可能因为超时而失败。</p><p>除了用 <code>scroll api</code>，你也可以用 <code>search_after</code> 来做，<code>search_after</code> 的思想是使用前一页的结果来帮助检索下一页的数据，显然，这种方式也不允许你随意翻页，你只能一页页往后翻。初始化时，需要使用一个唯一值的字段作为 sort 字段。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;es 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个问题是肯定要问的，说白了，就是看你有没有实际干过 es，因为啥？其实 es 性能并没有你想象中那么好的。很多时候数据量大了，特别是有几亿条数据的时候，可能你会懵逼的发现，跑个搜索怎么一下 &lt;code&gt;5~10s&lt;/code&gt;，坑爹了。第一次搜索的时候，是  &lt;code&gt;5~10s&lt;/code&gt;，后面反而就快了，可能就几百毫秒。&lt;/p&gt;
&lt;p&gt;你就很懵，每个用户第一次访问都会比较慢，比较卡么？所以你要是没玩儿过 es，或者就是自己玩玩儿 demo，被问到这个问题容易懵逼，显示出你对 es 确实玩儿的不怎么样？&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="搜索引擎" scheme="http://shenshanlaoyuan.com/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
</feed>
