<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>深山老猿</title>
  <icon>https://www.gravatar.com/avatar/337c5b9715d60466924c746da7df8603</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://shenshanlaoyuan.com/"/>
  <updated>2020-05-29T07:15:52.208Z</updated>
  <id>http://shenshanlaoyuan.com/</id>
  
  <author>
    <name>深山老猿</name>
    <email>wl4j@foxmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何自己设计一个类似Dubbo的RPC框架？</title>
    <link href="http://shenshanlaoyuan.com/2020/06/06/%E9%9D%A2%E8%AF%95/2020-6-6-%E5%A6%82%E4%BD%95%E8%87%AA%E5%B7%B1%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BCDubbo%E7%9A%84RPC%E6%A1%86%E6%9E%B6%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/06/06/面试/2020-6-6-如何自己设计一个类似Dubbo的RPC框架？/</id>
    <published>2020-06-06T03:52:00.000Z</published>
    <updated>2020-05-29T07:15:52.208Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何自己设计一个类似 Dubbo 的 RPC 框架？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>说实话，就这问题，其实就跟问你如何自己设计一个 MQ 一样的道理，就考两个：</p><ul><li>你有没有对某个 rpc 框架原理有非常深入的理解。</li><li>你能不能从整体上来思考一下，如何设计一个 rpc 框架，考考你的系统设计能力。</li></ul><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/06/06/面试/2020-6-6-如何自己设计一个类似Dubbo的RPC框架？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/06/06/面试/2020-6-6-如何自己设计一个类似Dubbo的RPC框架？/'>如何自己设计一个类似Dubbo的RPC框架？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实问到你这问题，你起码不能认怂，因为是知识的扫盲，那我不可能给你深入讲解什么 kafka 源码剖析，dubbo 源码剖析，何况我就算讲了，你要真的消化理解和吸收，起码个把月以后了。</p><p>所以我给大家一个建议，遇到这类问题，起码从你了解的类似框架的原理入手，自己说说参照 dubbo 的原理，你来设计一下，举个例子，dubbo 不是有那么多分层么？而且每个分层是干啥的，你大概是不是知道？那就按照这个思路大致说一下吧，起码你不能懵逼，要比那些上来就懵，啥也说不出来的人要好一些。</p><p>举个栗子，我给大家说个最简单的回答思路：</p><ul><li>上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信息，可以用 zookeeper 来做，对吧。</li><li>然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上。</li><li>接着你就该发起一次请求了，咋发起？当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。</li><li>然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是。</li><li>接着找到一台机器，就可以跟它发送请求了，第一个问题咋发送？你可以说用 netty 了，nio 方式；第二个问题发送啥格式数据？你可以说用 hessian 序列化协议了，或者是别的，对吧。然后请求过去了。</li><li>服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。</li></ul><p>这就是一个最最基本的 rpc 框架的思路，先不说你有多牛逼的技术功底，哪怕这个最简单的思路你先给出来行不行？</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何自己设计一个类似 Dubbo 的 RPC 框架？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;说实话，就这问题，其实就跟问你如何自己设计一个 MQ 一样的道理，就考两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你有没有对某个 rpc 框架原理有非常深入的理解。&lt;/li&gt;
&lt;li&gt;你能不能从整体上来思考一下，如何设计一个 rpc 框架，考考你的系统设计能力。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>分布式服务接口请求的顺序性如何保证？</title>
    <link href="http://shenshanlaoyuan.com/2020/06/05/%E9%9D%A2%E8%AF%95/2020-6-5-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%8F%A3%E8%AF%B7%E6%B1%82%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/06/05/面试/2020-6-5-分布式服务接口请求的顺序性如何保证？/</id>
    <published>2020-06-05T03:52:00.000Z</published>
    <updated>2020-05-29T07:14:43.464Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>分布式服务接口请求的顺序性如何保证？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实分布式系统接口的调用顺序，也是个问题，一般来说是不用保证顺序的。但是<strong>有时候</strong>可能确实是需要<strong>严格的顺序</strong>保证。给大家举个例子，你服务 A 调用服务 B，先插入再删除。好，结果俩请求过去了，落在不同机器上，可能插入请求因为某些原因执行慢了一些，导致删除请求先执行了，此时因为没数据所以啥效果也没有；结果这个时候插入请求过来了，好，数据插入进去了，那就尴尬了。</p><p>本来应该是 “先插入 -&gt; 再删除”，这条数据应该没了，结果现在 “先删除 -&gt; 再插入”，数据还存在，最后你死都想不明白是怎么回事。</p><p>所以这都是分布式系统一些很常见的问题。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/06/05/面试/2020-6-5-分布式服务接口请求的顺序性如何保证？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/06/05/面试/2020-6-5-分布式服务接口请求的顺序性如何保证？/'>分布式服务接口请求的顺序性如何保证？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>首先，一般来说，个人建议是，你们从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，因为一旦引入顺序性保障，比如使用<strong>分布式锁</strong>，会<strong>导致系统复杂度上升</strong>，而且会带来<strong>效率低下</strong>，热点数据压力过大等问题。</p><p>下面我给个我们用过的方案吧，简单来说，首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上，因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个<strong>内存队列</strong>里去，强制排队，这样来确保他们的顺序性。</p><p><img src="https://i.loli.net/2020/05/29/cLQqhnNAdpCrz3F.png" alt="distributed-system-request-sequence.png"></p><p>但是这样引发的后续问题就很多，比如说要是某个订单对应的请求特别多，造成某台机器成<strong>热点</strong>怎么办？解决这些问题又要开启后续一连串的复杂技术方案……曾经这类问题弄的我们头疼不已，所以，还是建议什么呢？</p><p>最好是比如说刚才那种，一个订单的插入和删除操作，能不能合并成一个操作，就是一个删除，或者是其它什么，避免这种问题的产生。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;分布式服务接口请求的顺序性如何保证？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实分布式系统接口的调用顺序，也是个问题，一般来说是不用保证顺序的。但是&lt;strong&gt;有时候&lt;/strong&gt;可能确实是需要&lt;strong&gt;严格的顺序&lt;/strong&gt;保证。给大家举个例子，你服务 A 调用服务 B，先插入再删除。好，结果俩请求过去了，落在不同机器上，可能插入请求因为某些原因执行慢了一些，导致删除请求先执行了，此时因为没数据所以啥效果也没有；结果这个时候插入请求过来了，好，数据插入进去了，那就尴尬了。&lt;/p&gt;
&lt;p&gt;本来应该是 “先插入 -&amp;gt; 再删除”，这条数据应该没了，结果现在 “先删除 -&amp;gt; 再插入”，数据还存在，最后你死都想不明白是怎么回事。&lt;/p&gt;
&lt;p&gt;所以这都是分布式系统一些很常见的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分布式" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式服务接口的幂等性如何设计？</title>
    <link href="http://shenshanlaoyuan.com/2020/06/04/%E9%9D%A2%E8%AF%95/2020-6-4-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/06/04/面试/2020-6-4-分布式服务接口的幂等性如何设计？/</id>
    <published>2020-06-04T03:52:00.000Z</published>
    <updated>2020-05-29T07:13:40.429Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>分布式服务接口的幂等性如何设计（比如不能重复扣款）？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>从这个问题开始，面试官就已经进入了<strong>实际的生产问题</strong>的面试了。</p><p>一个分布式系统中的某个接口，该如何保证幂等性？这个事儿其实是你做分布式系统的时候必须要考虑的一个生产环境的技术问题。啥意思呢？</p><p>你看，假如你有个服务提供一些接口供外部调用，这个服务部署在了 5 台机器上，接着有个接口就是<strong>付款接口</strong>。然后人家用户在前端上操作的时候，不知道为啥，总之就是一个订单<strong>不小心发起了两次支付请求</strong>，然后这俩请求分散在了这个服务部署的不同的机器上，好了，结果一个订单扣款扣两次。</p><p>或者是订单系统调用支付系统进行支付，结果不小心因为<strong>网络超时</strong>了，然后订单系统走了前面我们看到的那个重试机制，咔嚓给你重试了一把，好，支付系统收到一个支付请求两次，而且因为负载均衡算法落在了不同的机器上，尴尬了。。。</p><p>所以你肯定得知道这事儿，否则你做出来的分布式系统恐怕容易埋坑。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/06/04/面试/2020-6-4-分布式服务接口的幂等性如何设计？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/06/04/面试/2020-6-4-分布式服务接口的幂等性如何设计？/'>分布式服务接口的幂等性如何设计？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个不是技术问题，这个没有通用的一个方法，这个应该<strong>结合业务</strong>来保证幂等性。</p><p>所谓<strong>幂等性</strong>，就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，比如不能多扣款、不能多插入一条数据、不能将统计值多加了 1。这就是幂等性。</p><p>其实保证幂等性主要是三点：</p><ul><li>对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。</li><li>每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。</li><li>每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。</li></ul><p>实际运作过程中，你要结合自己的业务来，比如说利用 redis，用 orderId 作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款。</p><p>要求是支付一个订单，必须插入一条支付流水，order_id 建一个唯一键 <code>unique key</code>。你在支付一个订单之前，先插入一条支付流水，order_id 就已经进去了。你就可以写一个标识到 redis 里面去，<code>set order_id payed</code>，下一次重复请求过来了，先查 redis 的 order_id 对应的 value，如果是 <code>payed</code> 就说明已经支付过了，你就别重复支付了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;分布式服务接口的幂等性如何设计（比如不能重复扣款）？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;从这个问题开始，面试官就已经进入了&lt;strong&gt;实际的生产问题&lt;/strong&gt;的面试了。&lt;/p&gt;
&lt;p&gt;一个分布式系统中的某个接口，该如何保证幂等性？这个事儿其实是你做分布式系统的时候必须要考虑的一个生产环境的技术问题。啥意思呢？&lt;/p&gt;
&lt;p&gt;你看，假如你有个服务提供一些接口供外部调用，这个服务部署在了 5 台机器上，接着有个接口就是&lt;strong&gt;付款接口&lt;/strong&gt;。然后人家用户在前端上操作的时候，不知道为啥，总之就是一个订单&lt;strong&gt;不小心发起了两次支付请求&lt;/strong&gt;，然后这俩请求分散在了这个服务部署的不同的机器上，好了，结果一个订单扣款扣两次。&lt;/p&gt;
&lt;p&gt;或者是订单系统调用支付系统进行支付，结果不小心因为&lt;strong&gt;网络超时&lt;/strong&gt;了，然后订单系统走了前面我们看到的那个重试机制，咔嚓给你重试了一把，好，支付系统收到一个支付请求两次，而且因为负载均衡算法落在了不同的机器上，尴尬了。。。&lt;/p&gt;
&lt;p&gt;所以你肯定得知道这事儿，否则你做出来的分布式系统恐怕容易埋坑。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分布式" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>如何基于Dubbo进行服务治理？</title>
    <link href="http://shenshanlaoyuan.com/2020/06/03/%E9%9D%A2%E8%AF%95/2020-6-3-%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8EDubbo%E8%BF%9B%E8%A1%8C%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/06/03/面试/2020-6-3-如何基于Dubbo进行服务治理？/</id>
    <published>2020-06-03T03:52:00.000Z</published>
    <updated>2020-05-29T07:12:32.245Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何基于 dubbo 进行服务治理、服务降级、失败重试以及超时重试？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>服务治理，这个问题如果问你，其实就是看看你有没有<strong>服务治理</strong>的思想，因为这个是做过复杂微服务的人肯定会遇到的一个问题。</p><p><strong>服务降级</strong>，这个是涉及到复杂分布式系统中必备的一个话题，因为分布式系统互相来回调用，任何一个系统故障了，你不降级，直接就全盘崩溃？那就太坑爹了吧。</p><p><strong>失败重试</strong>，分布式系统中网络请求如此频繁，要是因为网络问题不小心失败了一次，是不是要重试？</p><p><strong>超时重试</strong>，跟上面一样，如果不小心网络慢一点，超时了，如何重试？</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/06/03/面试/2020-6-3-如何基于Dubbo进行服务治理？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/06/03/面试/2020-6-3-如何基于Dubbo进行服务治理？/'>如何基于Dubbo进行服务治理？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="服务治理"><a href="#服务治理" class="headerlink" title="服务治理"></a>服务治理</h3><h4 id="1-调用链路自动生成"><a href="#1-调用链路自动生成" class="headerlink" title="1. 调用链路自动生成"></a>1. 调用链路自动生成</h4><p>一个大型的分布式系统，或者说是用现在流行的微服务架构来说吧，<strong>分布式系统由大量的服务组成</strong>。那么这些服务之间互相是如何调用的？调用链路是啥？说实话，几乎到后面没人搞的清楚了，因为服务实在太多了，可能几百个甚至几千个服务。</p><p>那就需要基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将<strong>各个服务之间的依赖关系和调用链路生成出来</strong>，做成一张图，显示出来，大家才可以看到对吧。</p><p><img src="https://i.loli.net/2020/05/29/txc5RaHbo2NBsIF.png" alt="dubbo-service-invoke-road.png"></p><h4 id="2-服务访问压力以及时长统计"><a href="#2-服务访问压力以及时长统计" class="headerlink" title="2. 服务访问压力以及时长统计"></a>2. 服务访问压力以及时长统计</h4><p>需要自动统计<strong>各个接口和服务之间的调用次数以及访问延时</strong>，而且要分成两个级别。</p><ul><li>一个级别是接口粒度，就是每个服务的每个接口每天被调用多少次，TP50/TP90/TP99，三个档次的请求延时分别是多少；</li><li>第二个级别是从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 TP50/TP90/TP99，分别是多少。</li></ul><p>这些东西都搞定了之后，后面才可以来看当前系统的压力主要在哪里，如何来扩容和优化啊。</p><h4 id="3-其它"><a href="#3-其它" class="headerlink" title="3. 其它"></a>3. 其它</h4><ul><li>服务分层（避免循环依赖）</li><li>调用链路失败监控和报警</li><li>服务鉴权</li><li>每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%）</li></ul><h3 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h3><p>比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。</p><p>举个栗子，我们有接口 <code>HelloService</code>。<code>HelloServiceImpl</code> 有该接口的具体实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HelloService</span> </span>&#123;</div><div class="line">   <span class="function"><span class="keyword">void</span> <span class="title">sayHello</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceImpl</span> <span class="keyword">implements</span> <span class="title">HelloService</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sayHello</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"hello world......"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></div><div class="line">    <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> <span class="attr">xmlns:dubbo</span>=<span class="string">"http://code.alibabatech.com/schema/dubbo"</span></div><div class="line">    <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd"</span>&gt;</div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:application</span> <span class="attr">name</span>=<span class="string">"dubbo-provider"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:protocol</span> <span class="attr">name</span>=<span class="string">"dubbo"</span> <span class="attr">port</span>=<span class="string">"20880"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">interface</span>=<span class="string">"com.zhss.service.HelloService"</span> <span class="attr">ref</span>=<span class="string">"helloServiceImpl"</span> <span class="attr">timeout</span>=<span class="string">"10000"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"helloServiceImpl"</span> <span class="attr">class</span>=<span class="string">"com.zhss.service.HelloServiceImpl"</span> /&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></div><div class="line"></div><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span></span></div><div class="line">    <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></div><div class="line">    <span class="attr">xmlns:dubbo</span>=<span class="string">"http://code.alibabatech.com/schema/dubbo"</span></div><div class="line">    <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd"</span>&gt;</div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:application</span> <span class="attr">name</span>=<span class="string">"dubbo-consumer"</span>  /&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181"</span> /&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">id</span>=<span class="string">"fooService"</span> <span class="attr">interface</span>=<span class="string">"com.test.service.FooService"</span>  <span class="attr">timeout</span>=<span class="string">"10000"</span> <span class="attr">check</span>=<span class="string">"false"</span> <span class="attr">mock</span>=<span class="string">"return null"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">dubbo:reference</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></div></pre></td></tr></table></figure><p>我们调用接口失败的时候，可以通过 <code>mock</code> 统一返回 null。</p><p>mock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+<code>Mock</code>” 后缀。然后在 Mock 类里实现自己的降级逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceMock</span> <span class="keyword">implements</span> <span class="title">HelloService</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sayHello</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">// 降级逻辑</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="失败重试和超时重试"><a href="#失败重试和超时重试" class="headerlink" title="失败重试和超时重试"></a>失败重试和超时重试</h3><p>所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。配置如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">id</span>=<span class="string">"xxxx"</span> <span class="attr">interface</span>=<span class="string">"xx"</span> <span class="attr">check</span>=<span class="string">"true"</span> <span class="attr">async</span>=<span class="string">"false"</span> <span class="attr">retries</span>=<span class="string">"3"</span> <span class="attr">timeout</span>=<span class="string">"2000"</span>/&gt;</span></div></pre></td></tr></table></figure><p>举个栗子。</p><p>某个服务的接口，要耗费 5s，你这边不能干等着，你这边配置了 timeout 之后，我等待 2s，还没返回，我直接就撤了，不能干等你。</p><p>可以结合你们公司具体的场景来说说你是怎么设置这些参数的：</p><ul><li><code>timeout</code>：一般设置为 <code>200ms</code>，我们认为不能超过 <code>200ms</code> 还没返回。</li><li><code>retries</code>：设置 retries，一般是在读请求的时候，比如你要查询个数据，你可以设置个 retries，如果第一次没读到，报错，重试指定的次数，尝试再次读取。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何基于 dubbo 进行服务治理、服务降级、失败重试以及超时重试？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;服务治理，这个问题如果问你，其实就是看看你有没有&lt;strong&gt;服务治理&lt;/strong&gt;的思想，因为这个是做过复杂微服务的人肯定会遇到的一个问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务降级&lt;/strong&gt;，这个是涉及到复杂分布式系统中必备的一个话题，因为分布式系统互相来回调用，任何一个系统故障了，你不降级，直接就全盘崩溃？那就太坑爹了吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;失败重试&lt;/strong&gt;，分布式系统中网络请求如此频繁，要是因为网络问题不小心失败了一次，是不是要重试？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;超时重试&lt;/strong&gt;，跟上面一样，如果不小心网络慢一点，超时了，如何重试？&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo的spi思想是什么？</title>
    <link href="http://shenshanlaoyuan.com/2020/06/02/%E9%9D%A2%E8%AF%95/2020-6-2-Dubbo%E7%9A%84spi%E6%80%9D%E6%83%B3%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/06/02/面试/2020-6-2-Dubbo的spi思想是什么？/</id>
    <published>2020-06-02T03:52:00.000Z</published>
    <updated>2020-05-29T07:11:10.857Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>dubbo 的 spi 思想是什么？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>继续深入问呗，前面一些基础性的东西问完了，确定你应该都 ok，了解 dubbo 的一些基本东西，那么问个稍微难一点点的问题，就是 spi，先问问你 spi 是啥？然后问问你 dubbo 的 spi 是怎么实现的？</p><p>其实就是看看你对 dubbo 的掌握如何。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/06/02/面试/2020-6-2-Dubbo的spi思想是什么？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/06/02/面试/2020-6-2-Dubbo的spi思想是什么？/'>Dubbo的spi思想是什么？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="spi-是啥？"><a href="#spi-是啥？" class="headerlink" title="spi 是啥？"></a>spi 是啥？</h3><p>spi，简单来说，就是 <code>service provider interface</code>，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要<strong>根据指定的配置</strong>或者是<strong>默认的配置</strong>，去<strong>找到对应的实现类</strong>加载进来，然后用这个实现类的实例对象。</p><p>举个栗子。</p><p>你有一个接口 A。A1/A2/A3 分别是接口A的不同实现。你通过配置 <code>接口 A = 实现 A2</code>，那么在系统实际运行的时候，会加载你的配置，用实现 A2 实例化一个对象来提供服务。</p><p>spi 机制一般用在哪儿？<strong>插件扩展的场景</strong>，比如说你开发了一个给别人使用的开源框架，如果你想让别人自己写个插件，插到你的开源框架里面，从而扩展某个功能，这个时候 spi 思想就用上了。</p><h3 id="Java-spi-思想的体现"><a href="#Java-spi-思想的体现" class="headerlink" title="Java spi 思想的体现"></a>Java spi 思想的体现</h3><p>spi 经典的思想体现，大家平时都在用，比如说 jdbc。</p><p>Java 定义了一套 jdbc 的接口，但是 Java 并没有提供 jdbc 的实现类。</p><p>但是实际上项目跑的时候，要使用 jdbc 接口的哪些实现类呢？一般来说，我们要<strong>根据自己使用的数据库</strong>，比如 mysql，你就将 <code>mysql-jdbc-connector.jar</code> 引入进来；oracle，你就将 <code>oracle-jdbc-connector.jar</code> 引入进来。</p><p>在系统跑的时候，碰到你使用 jdbc 的接口，他会在底层使用你引入的那个 jar 中提供的实现类。</p><h3 id="dubbo-的-spi-思想"><a href="#dubbo-的-spi-思想" class="headerlink" title="dubbo 的 spi 思想"></a>dubbo 的 spi 思想</h3><p>dubbo 也用了 spi 思想，不过没有用 jdk 的 spi 机制，是自己实现的一套 spi 机制。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();</div></pre></td></tr></table></figure></p><p>Protocol 接口，在系统运行的时候，，dubbo 会判断一下应该选用这个 Protocol 接口的哪个实现类来实例化对象来使用。</p><p>它会去找一个你配置的 Protocol，将你配置的 Protocol 实现类，加载到 jvm 中来，然后实例化对象，就用你的那个 Protocol 实现类就可以了。</p><p>上面那行代码就是 dubbo 里大量使用的，就是对很多组件，都是保留一个接口和多个实现，然后在系统运行的时候动态根据配置去找到对应的实现类。如果你没配置，那就走默认的实现好了，没问题。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@SPI</span>(<span class="string">"dubbo"</span>)  </div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Protocol</span> </span>&#123;  </div><div class="line">      </div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getDefaultPort</span><span class="params">()</span></span>;  </div><div class="line">  </div><div class="line">    <span class="meta">@Adaptive</span>  </div><div class="line">    &lt;T&gt; <span class="function">Exporter&lt;T&gt; <span class="title">export</span><span class="params">(Invoker&lt;T&gt; invoker)</span> <span class="keyword">throws</span> RpcException</span>;  </div><div class="line">  </div><div class="line">    <span class="meta">@Adaptive</span>  </div><div class="line">    &lt;T&gt; <span class="function">Invoker&lt;T&gt; <span class="title">refer</span><span class="params">(Class&lt;T&gt; type, URL url)</span> <span class="keyword">throws</span> RpcException</span>;  </div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span></span>;  </div><div class="line">  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>在 dubbo 自己的 jar 里，在<code>/META_INF/dubbo/internal/com.alibaba.dubbo.rpc.Protocol</code>文件中：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">dubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol</div><div class="line">http=com.alibaba.dubbo.rpc.protocol.http.HttpProtocol</div><div class="line">hessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocol</div></pre></td></tr></table></figure></p><p>所以说，这就看到了 dubbo 的 spi 机制默认是怎么玩儿的了，其实就是 Protocol 接口，<code>@SPI(&quot;dubbo&quot;)</code> 说的是，通过 SPI 机制来提供实现类，实现类是通过 dubbo 作为默认 key 去配置文件里找到的，配置文件名称与接口全限定名一样的，通过 dubbo 作为 key 可以找到默认的实现类就是 <code>com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol</code>。</p><p>如果想要动态替换掉默认的实现类，需要使用 <code>@Adaptive</code> 接口，Protocol 接口中，有两个方法加了 <code>@Adaptive</code> 注解，就是说那俩接口会被代理实现。</p><p>啥意思呢？</p><p>比如这个 Protocol 接口搞了俩 <code>@Adaptive</code> 注解标注了方法，在运行的时候会针对 Protocol 生成代理类，这个代理类的那俩方法里面会有代理代码，代理代码会在运行的时候动态根据 url 中的 protocol 来获取那个 key，默认是 dubbo，你也可以自己指定，你如果指定了别的 key，那么就会获取别的实现类的实例了。</p><h3 id="如何自己扩展-dubbo-中的组件"><a href="#如何自己扩展-dubbo-中的组件" class="headerlink" title="如何自己扩展 dubbo 中的组件"></a>如何自己扩展 dubbo 中的组件</h3><p>下面来说说怎么来自己扩展 dubbo 中的组件。</p><p>自己写个工程，要是那种可以打成 jar 包的，里面的 <code>src/main/resources</code> 目录下，搞一个 <code>META-INF/services</code>，里面放个文件叫：<code>com.alibaba.dubbo.rpc.Protocol</code>，文件里搞一个<code>my=com.bingo.MyProtocol</code>。自己把 jar 弄到 nexus 私服里去。</p><p>然后自己搞一个 <code>dubbo provider</code> 工程，在这个工程里面依赖你自己搞的那个 jar，然后在 spring 配置文件里给个配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:protocol</span> <span class="attr">name</span>=<span class="string">”my”</span> <span class="attr">port</span>=<span class="string">”20000”</span> /&gt;</span></div></pre></td></tr></table></figure><p>provider 启动的时候，就会加载到我们 jar 包里的<code>my=com.bingo.MyProtocol</code> 这行配置里，接着会根据你的配置使用你定义好的 MyProtocol 了，这个就是简单说明一下，你通过上述方式，可以替换掉大量的 dubbo 内部的组件，就是扔个你自己的 jar 包，然后配置一下即可。</p><p><img src="https://i.loli.net/2020/05/29/lXOJUEf9tARVe2w.png" alt="dubbo-spi.png"></p><p>dubbo 里面提供了大量的类似上面的扩展点，就是说，你如果要扩展一个东西，只要自己写个 jar，让你的 consumer 或者是 provider 工程，依赖你的那个 jar，在你的 jar 里指定目录下配置好接口名称对应的文件，里面通过 <code>key=实现类</code>。</p><p>然后对于对应的组件，类似 <code>&lt;dubbo:protocol&gt;</code> 用你的那个  key 对应的实现类来实现某个接口，你可以自己去扩展 dubbo 的各种功能，提供你自己的实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;dubbo 的 spi 思想是什么？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;继续深入问呗，前面一些基础性的东西问完了，确定你应该都 ok，了解 dubbo 的一些基本东西，那么问个稍微难一点点的问题，就是 spi，先问问你 spi 是啥？然后问问你 dubbo 的 spi 是怎么实现的？&lt;/p&gt;
&lt;p&gt;其实就是看看你对 dubbo 的掌握如何。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo负载均衡策略和集群容错策略？</title>
    <link href="http://shenshanlaoyuan.com/2020/06/01/%E9%9D%A2%E8%AF%95/2020-6-1-Dubbo%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E5%92%8C%E9%9B%86%E7%BE%A4%E5%AE%B9%E9%94%99%E7%AD%96%E7%95%A5%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/06/01/面试/2020-6-1-Dubbo负载均衡策略和集群容错策略？/</id>
    <published>2020-06-01T03:52:00.000Z</published>
    <updated>2020-05-29T07:09:52.360Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>继续深问吧，这些都是用 dubbo 必须知道的一些东西，你得知道基本原理，知道序列化是什么协议，还得知道具体用 dubbo 的时候，如何负载均衡，如何高可用，如何动态代理。</p><p>说白了，就是看你对 dubbo 熟悉不熟悉：</p><ul><li>dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡；</li><li>网络通信、序列化：dubbo 协议、长连接、NIO、hessian 序列化协议；</li><li>负载均衡策略、集群容错策略、动态代理策略：dubbo 跑起来的时候一些功能是如何运转的？怎么做负载均衡？怎么做集群容错？怎么生成动态代理？</li><li>dubbo SPI 机制：你了解不了解 dubbo 的 SPI 机制？如何基于 SPI 机制对 dubbo 进行扩展？</li></ul><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/06/01/面试/2020-6-1-Dubbo负载均衡策略和集群容错策略？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/06/01/面试/2020-6-1-Dubbo负载均衡策略和集群容错策略？/'>Dubbo负载均衡策略和集群容错策略？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="dubbo-负载均衡策略"><a href="#dubbo-负载均衡策略" class="headerlink" title="dubbo 负载均衡策略"></a>dubbo 负载均衡策略</h3><h4 id="random-loadbalance"><a href="#random-loadbalance" class="headerlink" title="random loadbalance"></a>random loadbalance</h4><p>默认情况下，dubbo 是 random load balance ，即<strong>随机</strong>调用实现负载均衡，可以对 provider 不同实例<strong>设置不同的权重</strong>，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。</p><h4 id="roundrobin-loadbalance"><a href="#roundrobin-loadbalance" class="headerlink" title="roundrobin loadbalance"></a>roundrobin loadbalance</h4><p>这个的话默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。</p><p>举个栗子。</p><p>跟运维同学申请机器，有的时候，我们运气好，正好公司资源比较充足，刚刚有一批热气腾腾、刚刚做好的虚拟机新鲜出炉，配置都比较高：8 核 + 16G 机器，申请到 2 台。过了一段时间，我们感觉 2 台机器有点不太够，我就去找运维同学说，“哥儿们，你能不能再给我一台机器”，但是这时只剩下一台 4 核 + 8G 的机器。我要还是得要。</p><p>这个时候，可以给两台 8 核 16G 的机器设置权重 4，给剩余 1 台 4 核 8G 的机器设置权重 2。</p><h4 id="leastactive-loadbalance"><a href="#leastactive-loadbalance" class="headerlink" title="leastactive loadbalance"></a>leastactive loadbalance</h4><p>这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给<strong>不活跃的性能差的机器更少的请求</strong>。</p><h4 id="consistanthash-loadbalance"><a href="#consistanthash-loadbalance" class="headerlink" title="consistanthash loadbalance"></a>consistanthash loadbalance</h4><p>一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。<strong>如果你需要的不是随机负载均衡</strong>，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。</p><h3 id="dubbo-集群容错策略"><a href="#dubbo-集群容错策略" class="headerlink" title="dubbo 集群容错策略"></a>dubbo 集群容错策略</h3><h4 id="failover-cluster-模式"><a href="#failover-cluster-模式" class="headerlink" title="failover cluster 模式"></a>failover cluster 模式</h4><p>失败自动切换，自动重试其他机器，<strong>默认</strong>就是这个，常见于读操作。（失败重试其它机器）</p><p>可以通过以下几种方式配置重试次数：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">retries</span>=<span class="string">"2"</span> /&gt;</span></div></pre></td></tr></table></figure><p>或者</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">retries</span>=<span class="string">"2"</span> /&gt;</span></div></pre></td></tr></table></figure><p>或者</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">dubbo:method</span> <span class="attr">name</span>=<span class="string">"findFoo"</span> <span class="attr">retries</span>=<span class="string">"2"</span> /&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dubbo:reference</span>&gt;</span></div></pre></td></tr></table></figure><h4 id="failfast-cluster-模式"><a href="#failfast-cluster-模式" class="headerlink" title="failfast cluster 模式"></a>failfast cluster 模式</h4><p>一次调用失败就立即失败，常见于非幂等性的写操作，比如新增一条记录（调用失败就立即失败）</p><h4 id="failsafe-cluster-模式"><a href="#failsafe-cluster-模式" class="headerlink" title="failsafe cluster 模式"></a>failsafe cluster 模式</h4><p>出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。</p><p>配置示例如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">cluster</span>=<span class="string">"failsafe"</span> /&gt;</span></div></pre></td></tr></table></figure><p>或者</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">cluster</span>=<span class="string">"failsafe"</span> /&gt;</span></div></pre></td></tr></table></figure><h4 id="failback-cluster-模式"><a href="#failback-cluster-模式" class="headerlink" title="failback cluster 模式"></a>failback cluster 模式</h4><p>失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。</p><h4 id="forking-cluster-模式"><a href="#forking-cluster-模式" class="headerlink" title="forking cluster 模式"></a>forking cluster 模式</h4><p><strong>并行调用</strong>多个 provider，只要一个成功就立即返回。常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可通过 <code>forks=&quot;2&quot;</code> 来设置最大并行数。</p><h4 id="broadcacst-cluster"><a href="#broadcacst-cluster" class="headerlink" title="broadcacst cluster"></a>broadcacst cluster</h4><p>逐个调用所有的 provider。任何一个 provider 出错则报错（从<code>2.1.0</code> 版本开始支持）。通常用于通知所有提供者更新缓存或日志等本地资源信息。</p><h3 id="dubbo动态代理策略"><a href="#dubbo动态代理策略" class="headerlink" title="dubbo动态代理策略"></a>dubbo动态代理策略</h3><p>默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;继续深问吧，这些都是用 dubbo 必须知道的一些东西，你得知道基本原理，知道序列化是什么协议，还得知道具体用 dubbo 的时候，如何负载均衡，如何高可用，如何动态代理。&lt;/p&gt;
&lt;p&gt;说白了，就是看你对 dubbo 熟悉不熟悉：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡；&lt;/li&gt;
&lt;li&gt;网络通信、序列化：dubbo 协议、长连接、NIO、hessian 序列化协议；&lt;/li&gt;
&lt;li&gt;负载均衡策略、集群容错策略、动态代理策略：dubbo 跑起来的时候一些功能是如何运转的？怎么做负载均衡？怎么做集群容错？怎么生成动态代理？&lt;/li&gt;
&lt;li&gt;dubbo SPI 机制：你了解不了解 dubbo 的 SPI 机制？如何基于 SPI 机制对 dubbo 进行扩展？&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo支持哪些序列化协议？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/31/%E9%9D%A2%E8%AF%95/2020-5-31-Dubbo%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/31/面试/2020-5-31-Dubbo支持哪些序列化协议？/</id>
    <published>2020-05-31T03:52:00.000Z</published>
    <updated>2020-05-29T07:08:26.849Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>dubbo 支持哪些通信协议？支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>上一个问题，说说 dubbo 的基本工作原理，那是你必须知道的，至少要知道 dubbo 分成哪些层，然后平时怎么发起 rpc 请求的，注册、发现、调用，这些是基本的。</p><p>接着就可以针对底层进行深入的问问了，比如第一步就可以先问问序列化协议这块，就是平时 RPC 的时候怎么走的？</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/31/面试/2020-5-31-Dubbo支持哪些序列化协议？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/31/面试/2020-5-31-Dubbo支持哪些序列化协议？/'>Dubbo支持哪些序列化协议？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p><strong>序列化</strong>，就是把数据结构或者是一些对象，转换为二进制串的过程，而<strong>反序列化</strong>是将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程。</p><p><img src="https://i.loli.net/2020/05/29/LDPrkMz4evaFGho.png" alt="serialize-deserialize.png"></p><h3 id="dubbo-支持不同的通信协议"><a href="#dubbo-支持不同的通信协议" class="headerlink" title="dubbo 支持不同的通信协议"></a>dubbo 支持不同的通信协议</h3><ul><li>dubbo 协议</li></ul><p><strong>默认</strong>就是走 dubbo 协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。</p><p>为了要支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次！此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接就可以，可能总共就 100 个连接。然后后面直接基于长连接 NIO 异步通信，可以支撑高并发请求。</p><p>长连接，通俗点说，就是建立连接过后可以持续发送请求，无须再建立连接。</p><p><img src="https://i.loli.net/2020/05/29/97NEgbJeUuFvD86.png" alt="dubbo-keep-connection.png"></p><p>而短连接，每次要发送请求之前，需要先重新建立一次连接。</p><p><img src="https://i.loli.net/2020/05/29/v2zKMctbQP3ZB48.png" alt="dubbo-not-keep-connection.png"></p><ul><li>rmi 协议</li></ul><p>走 Java 二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。</p><ul><li>hessian 协议</li></ul><p>走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。</p><ul><li>http 协议</li></ul><p>走 json 序列化。</p><ul><li>webservice</li></ul><p>走 SOAP 文本序列化。</p><h3 id="dubbo-支持的序列化协议"><a href="#dubbo-支持的序列化协议" class="headerlink" title="dubbo 支持的序列化协议"></a>dubbo 支持的序列化协议</h3><p>dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。</p><h3 id="说一下-Hessian-的数据结构"><a href="#说一下-Hessian-的数据结构" class="headerlink" title="说一下 Hessian 的数据结构"></a>说一下 Hessian 的数据结构</h3><p>Hessian 的对象序列化机制有 8 种原始类型：</p><ul><li>原始二进制数据</li><li>boolean</li><li>64-bit date（64 位毫秒值的日期）</li><li>64-bit double</li><li>32-bit int</li><li>64-bit long</li><li>null</li><li>UTF-8 编码的 string</li></ul><p>另外还包括 3 种递归类型：</p><ul><li>list for lists and arrays</li><li>map for maps and dictionaries</li><li>object for objects</li></ul><p>还有一种特殊的类型：</p><ul><li>ref：用来表示对共享对象的引用。</li></ul><h3 id="为什么-PB-的效率是最高的？"><a href="#为什么-PB-的效率是最高的？" class="headerlink" title="为什么 PB 的效率是最高的？"></a>为什么 PB 的效率是最高的？</h3><p>可能有一些同学比较习惯于 <code>JSON</code> or <code>XML</code> 数据存储格式，对于 <code>Protocol Buffer</code> 还比较陌生。<code>Protocol Buffer</code> 其实是 Google 出品的一种轻量并且高效的结构化数据存储格式，性能比 <code>JSON</code>、<code>XML</code> 要高很多。</p><p>其实 PB 之所以性能如此好，主要得益于两个：<strong>第一</strong>，它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 <code>XML</code> 和 <code>JSON</code> 快上了 <code>20~100</code> 倍；<strong>第二</strong>，它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;dubbo 支持哪些通信协议？支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;上一个问题，说说 dubbo 的基本工作原理，那是你必须知道的，至少要知道 dubbo 分成哪些层，然后平时怎么发起 rpc 请求的，注册、发现、调用，这些是基本的。&lt;/p&gt;
&lt;p&gt;接着就可以针对底层进行深入的问问了，比如第一步就可以先问问序列化协议这块，就是平时 RPC 的时候怎么走的？&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>说一下 Dubbo 的工作原理？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/30/%E9%9D%A2%E8%AF%95/2020-5-30-%E8%AF%B4%E4%B8%80%E4%B8%8B-Dubbo-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/30/面试/2020-5-30-说一下-Dubbo-的工作原理？/</id>
    <published>2020-05-30T03:52:00.000Z</published>
    <updated>2020-05-29T07:06:38.707Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>说一下的 dubbo 的工作原理？注册中心挂了可以继续通信吗？说说一次 rpc 请求的流程？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>MQ、ES、Redis、Dubbo，上来先问你一些<strong>思考性的问题</strong>、<strong>原理</strong>，比如 kafka 高可用架构原理、es 分布式架构原理、redis 线程模型原理、Dubbo 工作原理；之后就是生产环境里可能会碰到的一些问题，因为每种技术引入之后生产环境都可能会碰到一些问题；再来点综合的，就是系统设计，比如让你设计一个 MQ、设计一个搜索引擎、设计一个缓存、设计一个 rpc 框架等等。</p><p>那既然开始聊分布式系统了，自然重点先聊聊 dubbo 了，毕竟 dubbo 是目前事实上大部分公司的分布式系统的 rpc 框架标准，基于 dubbo 也可以构建一整套的微服务架构。但是需要自己大量开发。</p><p>当然去年开始 spring cloud 非常火，现在大量的公司开始转向 spring cloud 了，spring cloud 人家毕竟是微服务架构的全家桶式的这么一个东西。但是因为很多公司还在用 dubbo，所以 dubbo 肯定会是目前面试的重点，何况人家 dubbo 现在重启开源社区维护了，捐献给了 apache，未来应该也还是有一定市场和地位的。</p><p>既然聊 dubbo，那肯定是先从 dubbo 原理开始聊了，你先说说 dubbo 支撑  rpc 分布式调用的架构啥的，然后说说一次 rpc 请求 dubbo 是怎么给你完成的，对吧。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/30/面试/2020-5-30-说一下-Dubbo-的工作原理？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/30/面试/2020-5-30-说一下-Dubbo-的工作原理？/'>说一下 Dubbo 的工作原理？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="dubbo-工作原理"><a href="#dubbo-工作原理" class="headerlink" title="dubbo 工作原理"></a>dubbo 工作原理</h3><ul><li>第一层：service 层，接口层，给服务提供者和消费者来实现的</li><li>第二层：config 层，配置层，主要是对 dubbo 进行各种配置的</li><li>第三层：proxy 层，服务代理层，无论是 consumer 还是 provider，dubbo 都会给你生成代理，代理之间进行网络通信</li><li>第四层：registry 层，服务注册层，负责服务的注册与发现</li><li>第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务</li><li>第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控</li><li>第七层：protocal 层，远程调用层，封装 rpc 调用</li><li>第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步</li><li>第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口</li><li>第十层：serialize 层，数据序列化层</li></ul><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ul><li>第一步：provider 向注册中心去注册</li><li>第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务</li><li>第三步：consumer 调用 provider</li><li>第四步：consumer 和 provider 都异步通知监控中心</li></ul><p><img src="https://i.loli.net/2020/05/29/jBGLbIOxCTeXlY3.png" alt="dubbo-operating-principle.png"></p><h3 id="注册中心挂了可以继续通信吗？"><a href="#注册中心挂了可以继续通信吗？" class="headerlink" title="注册中心挂了可以继续通信吗？"></a>注册中心挂了可以继续通信吗？</h3><p>可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息<strong>拉取到本地缓存</strong>，所以注册中心挂了可以继续通信。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;说一下的 dubbo 的工作原理？注册中心挂了可以继续通信吗？说说一次 rpc 请求的流程？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;MQ、ES、Redis、Dubbo，上来先问你一些&lt;strong&gt;思考性的问题&lt;/strong&gt;、&lt;strong&gt;原理&lt;/strong&gt;，比如 kafka 高可用架构原理、es 分布式架构原理、redis 线程模型原理、Dubbo 工作原理；之后就是生产环境里可能会碰到的一些问题，因为每种技术引入之后生产环境都可能会碰到一些问题；再来点综合的，就是系统设计，比如让你设计一个 MQ、设计一个搜索引擎、设计一个缓存、设计一个 rpc 框架等等。&lt;/p&gt;
&lt;p&gt;那既然开始聊分布式系统了，自然重点先聊聊 dubbo 了，毕竟 dubbo 是目前事实上大部分公司的分布式系统的 rpc 框架标准，基于 dubbo 也可以构建一整套的微服务架构。但是需要自己大量开发。&lt;/p&gt;
&lt;p&gt;当然去年开始 spring cloud 非常火，现在大量的公司开始转向 spring cloud 了，spring cloud 人家毕竟是微服务架构的全家桶式的这么一个东西。但是因为很多公司还在用 dubbo，所以 dubbo 肯定会是目前面试的重点，何况人家 dubbo 现在重启开源社区维护了，捐献给了 apache，未来应该也还是有一定市场和地位的。&lt;/p&gt;
&lt;p&gt;既然聊 dubbo，那肯定是先从 dubbo 原理开始聊了，你先说说 dubbo 支撑  rpc 分布式调用的架构啥的，然后说说一次 rpc 请求 dubbo 是怎么给你完成的，对吧。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>为什么要进行系统拆分？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/29/%E9%9D%A2%E8%AF%95/2020-5-29-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E7%B3%BB%E7%BB%9F%E6%8B%86%E5%88%86%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/29/面试/2020-5-29-为什么要进行系统拆分？/</id>
    <published>2020-05-29T03:52:00.000Z</published>
    <updated>2020-05-29T03:08:54.450Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>从这个问题开始就进行分布式系统环节了，现在出去面试分布式都成标配了，没有哪个公司不问问你分布式的事儿。你要是不会分布式的东西，简直这简历没法看，没人会让你去面试。</p><p>其实为啥会这样呢？这就是因为整个大行业技术发展的原因。</p><p>早些年，印象中在 2010 年初的时候，整个 IT 行业，很少有人谈分布式，更不用说微服务，虽然很多 BAT 等大型公司，因为系统的复杂性，很早就是分布式架构，大量的服务，只不过微服务大多基于自己搞的一套框架来实现而已。</p><p>但是确实，那个年代，大家很重视 ssh2，很多中小型公司几乎大部分都是玩儿 struts2、spring、hibernate，稍晚一些，才进入了 spring mvc、spring、mybatis 的组合。那个时候整个行业的技术水平就是那样，当年 oracle 很火，oracle 管理员很吃香，oracle 性能优化啥的都是 IT 男的大杀招啊。连大数据都没人提，当年 OCP、OCM 等认证培训机构，火的不行。</p><p>但是确实随着时代的发展，慢慢的，很多公司开始接受分布式系统架构了，这里面尤为对行业有至关重要影响的，是阿里的 dubbo，<strong>某种程度上而言，阿里在这里推动了行业技术的前进</strong>。</p><p>正是因为有阿里的 dubbo，很多中小型公司才可以基于 dubbo，来把系统拆分成很多的服务，每个人负责一个服务，大家的代码都没有冲突，服务可以自治，自己选用什么技术都可以，每次发布如果就改动一个服务那就上线一个服务好了，不用所有人一起联调，每次发布都是几十万行代码，甚至几百万行代码了。</p><p>直到今日，很高兴看到分布式系统都成行业面试标配了，任何一个普通的程序员都该掌握这个东西，其实这是行业的进步，也是所有 IT 码农的技术进步。所以既然分布式都成标配了，那么面试官当然会问了，因为很多公司现在都是分布式、微服务的架构，那面试官当然得考察考察你了。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/29/面试/2020-5-29-为什么要进行系统拆分？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/29/面试/2020-5-29-为什么要进行系统拆分？/'>为什么要进行系统拆分？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么要将系统进行拆分？"><a href="#为什么要将系统进行拆分？" class="headerlink" title="为什么要将系统进行拆分？"></a>为什么要将系统进行拆分？</h3><p>网上查查，答案极度零散和复杂，很琐碎，原因一大坨。但是我这里给大家直观的感受：</p><p>要是<strong>不拆分</strong>，一个大系统几十万行代码，20 个人维护一份代码，简直是悲剧啊。代码经常改着改着就冲突了，各种代码冲突和合并要处理，非常耗费时间；经常我改动了我的代码，你调用了我的，导致你的代码也得重新测试，麻烦的要死；然后每次发布都是几十万行代码的系统一起发布，大家得一起提心吊胆准备上线，几十万行代码的上线，可能每次上线都要做很多的检查，很多异常问题的处理，简直是又麻烦又痛苦；而且如果我现在打算把技术升级到最新的 spring 版本，还不行，因为这可能导致你的代码报错，我不敢随意乱改技术。</p><p>假设一个系统是 20 万行代码，其中 A 在里面改了 1000 行代码，但是此时发布的时候是这个 20 万行代码的大系统一块儿发布。就意味着 20 万上代码在线上就可能出现各种变化，20 个人，每个人都要紧张地等在电脑面前，上线之后，检查日志，看自己负责的那一块儿有没有什么问题。</p><p>A 就检查了自己负责的 1 万行代码对应的功能，确保 ok 就闪人了；结果不巧的是，A 上线的时候不小心修改了线上机器的某个配置，导致另外 B 和 C 负责的 2 万行代码对应的一些功能，出错了。</p><p>几十个人负责维护一个几十万行代码的单块应用，每次上线，准备几个礼拜，上线 -&gt; 部署 -&gt; 检查自己负责的功能。</p><p><strong>拆分了以后</strong>，整个世界清爽了，几十万行代码的系统，拆分成 20 个服务，平均每个服务就 1~2 万行代码，每个服务部署到单独的机器上。20 个工程，20 个 git 代码仓库，20 个开发人员，每个人维护自己的那个服务就可以了，是自己独立的代码，跟别人没关系。再也没有代码冲突了，爽。每次就测试我自己的代码就可以了，爽。每次就发布我自己的一个小服务就可以了，爽。技术上想怎么升级就怎么升级，保持接口不变就可以了，真爽。</p><p>所以简单来说，一句话总结，如果是那种代码量多达几十万行的中大型项目，团队里有几十个人，那么如果不拆分系统，<strong>开发效率极其低下</strong>，问题很多。但是拆分系统之后，每个人就负责自己的一小部分就好了，可以随便玩儿随便弄。分布式系统拆分之后，可以大幅度提升复杂系统大型团队的开发效率。</p><p>但是同时，也要<strong>提醒</strong>的一点是，系统拆分成分布式系统之后，大量的分布式系统面临的问题也是接踵而来，所以后面的问题都是在<strong>围绕分布式系统带来的复杂技术挑战</strong>在说。</p><h3 id="如何进行系统拆分？"><a href="#如何进行系统拆分？" class="headerlink" title="如何进行系统拆分？"></a>如何进行系统拆分？</h3><p>这个问题说大可以很大，可以扯到领域驱动模型设计上去，说小了也很小，我不太想给大家太过于学术的说法，因为你也不可能背这个答案，过去了直接说吧。还是说的简单一点，大家自己到时候知道怎么回答就行了。</p><p>系统拆分为分布式系统，拆成多个服务，拆成微服务的架构，是需要拆很多轮的。并不是说上来一个架构师一次就给拆好了，而以后都不用拆。</p><p>第一轮；团队继续扩大，拆好的某个服务，刚开始是 1 个人维护 1 万行代码，后来业务系统越来越复杂，这个服务是 10 万行代码，5 个人；第二轮，1个服务 -&gt; 5个服务，每个服务 2 万行代码，每人负责一个服务。</p><p>如果是多人维护一个服务，最理想的情况下，几十个人，1 个人负责 1 个或 2~3 个服务；某个服务工作量变大了，代码量越来越多，某个同学，负责一个服务，代码量变成了 10 万行了，他自己不堪重负，他现在一个人拆开，5 个服务，1 个人顶着，负责 5 个人，接着招人，2 个人，给那个同学带着，3 个人负责 5 个服务，其中 2 个人每个人负责 2 个服务，1 个人负责 1 个服务。</p><p>个人建议，一个服务的代码不要太多，1 万行左右，两三万撑死了吧。</p><p>大部分的系统，是要进行<strong>多轮拆分</strong>的，第一次拆分，可能就是将以前的多个模块该拆分开来了，比如说将电商系统拆分成订单系统、商品系统、采购系统、仓储系统、用户系统，等等吧。</p><p>但是后面可能每个系统又变得越来越复杂了，比如说采购系统里面又分成了供应商管理系统、采购单管理系统，订单系统又拆分成了购物车系统、价格系统、订单管理系统。</p><p>扯深了实在很深，所以这里先给大家举个例子，你自己感受一下，<strong>核心意思就是根据情况，先拆分一轮，后面如果系统更复杂了，可以继续分拆</strong>。你根据自己负责系统的例子，来考虑一下就好了。</p><h3 id="拆分后不用-dubbo-可以吗？"><a href="#拆分后不用-dubbo-可以吗？" class="headerlink" title="拆分后不用 dubbo 可以吗？"></a>拆分后不用 dubbo 可以吗？</h3><p>当然可以了，大不了最次，就是各个系统之间，直接基于 spring mvc，就纯 http 接口互相通信呗，还能咋样。但是这个肯定是有问题的，因为 http 接口通信维护起来成本很高，你要考虑<strong>超时重试</strong>、<strong>负载均衡</strong>等等各种乱七八糟的问题，比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。</p><p>所以 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡、服务实例上下线自动感知、超时重试等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;从这个问题开始就进行分布式系统环节了，现在出去面试分布式都成标配了，没有哪个公司不问问你分布式的事儿。你要是不会分布式的东西，简直这简历没法看，没人会让你去面试。&lt;/p&gt;
&lt;p&gt;其实为啥会这样呢？这就是因为整个大行业技术发展的原因。&lt;/p&gt;
&lt;p&gt;早些年，印象中在 2010 年初的时候，整个 IT 行业，很少有人谈分布式，更不用说微服务，虽然很多 BAT 等大型公司，因为系统的复杂性，很早就是分布式架构，大量的服务，只不过微服务大多基于自己搞的一套框架来实现而已。&lt;/p&gt;
&lt;p&gt;但是确实，那个年代，大家很重视 ssh2，很多中小型公司几乎大部分都是玩儿 struts2、spring、hibernate，稍晚一些，才进入了 spring mvc、spring、mybatis 的组合。那个时候整个行业的技术水平就是那样，当年 oracle 很火，oracle 管理员很吃香，oracle 性能优化啥的都是 IT 男的大杀招啊。连大数据都没人提，当年 OCP、OCM 等认证培训机构，火的不行。&lt;/p&gt;
&lt;p&gt;但是确实随着时代的发展，慢慢的，很多公司开始接受分布式系统架构了，这里面尤为对行业有至关重要影响的，是阿里的 dubbo，&lt;strong&gt;某种程度上而言，阿里在这里推动了行业技术的前进&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;正是因为有阿里的 dubbo，很多中小型公司才可以基于 dubbo，来把系统拆分成很多的服务，每个人负责一个服务，大家的代码都没有冲突，服务可以自治，自己选用什么技术都可以，每次发布如果就改动一个服务那就上线一个服务好了，不用所有人一起联调，每次发布都是几十万行代码，甚至几百万行代码了。&lt;/p&gt;
&lt;p&gt;直到今日，很高兴看到分布式系统都成行业面试标配了，任何一个普通的程序员都该掌握这个东西，其实这是行业的进步，也是所有 IT 码农的技术进步。所以既然分布式都成标配了，那么面试官当然会问了，因为很多公司现在都是分布式、微服务的架构，那面试官当然得考察考察你了。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Dubbo" scheme="http://shenshanlaoyuan.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>如何设计一个高并发系统？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/28/%E9%9D%A2%E8%AF%95/2020-5-28-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/28/面试/2020-5-28-如何设计一个高并发系统？/</id>
    <published>2020-05-28T03:52:00.000Z</published>
    <updated>2020-05-29T03:07:38.241Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何设计一个高并发系统？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>说实话，如果面试官问你这个题目，那么你必须要使出全身吃奶劲了。为啥？因为你没看到现在很多公司招聘的 JD 里都是说啥，有高并发就经验者优先。</p><p>如果你确实有真才实学，在互联网公司里干过高并发系统，那你确实拿 offer 基本如探囊取物，没啥问题。面试官也绝对不会这样来问你，否则他就是蠢。</p><p>假设你在某知名电商公司干过高并发系统，用户上亿，一天流量几十亿，高峰期并发量上万，甚至是十万。那么人家一定会仔细盘问你的系统架构，你们系统啥架构？怎么部署的？部署了多少台机器？缓存咋用的？MQ 咋用的？数据库咋用的？就是深挖你到底是如何扛住高并发的。</p><p>因为真正干过高并发的人一定知道，脱离了业务的系统架构都是在纸上谈兵，真正在复杂业务场景而且还高并发的时候，那系统架构一定不是那么简单的，用个 redis，用 mq 就能搞定？当然不是，真实的系统架构搭配上业务之后，会比这种简单的所谓“高并发架构”要复杂很多倍。</p><p>如果有面试官问你个问题说，如何设计一个高并发系统？那么不好意思，<strong>一定是因为你实际上没干过高并发系统</strong>。面试官看你简历就没啥出彩的，感觉就不咋地，所以就会问问你，如何设计一个高并发系统？其实说白了本质就是看看你有没有自己研究过，有没有一定的知识积累。</p><p>最好的当然是招聘个真正干过高并发的哥儿们咯，但是这种哥儿们人数稀缺，不好招。所以可能次一点的就是招一个自己研究过的哥儿们，总比招一个啥也不会的哥儿们好吧！</p><p>所以这个时候你必须得做一把个人秀了，秀出你所有关于高并发的知识！</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/28/面试/2020-5-28-如何设计一个高并发系统？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/28/面试/2020-5-28-如何设计一个高并发系统？/'>如何设计一个高并发系统？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实所谓的高并发，如果你要理解这个问题呢，其实就得从高并发的根源出发，为啥会有高并发？为啥高并发就很牛逼？</p><p>我说的浅显一点，很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p><p>当然会挂了，凭什么不挂？你数据库如果瞬间承载每秒 5000/8000，甚至上万的并发，一定会宕机，因为比如 mysql 就压根儿扛不住这么高的并发量。</p><p>所以为啥高并发牛逼？就是因为现在用互联网的人越来越多，很多 app、网站、系统承载的都是高并发请求，可能高峰期每秒并发量几千，很正常的。如果是什么双十一之类的，每秒并发几万几十万都有可能。</p><p>那么如此之高的并发量，加上原本就如此之复杂的业务，咋玩儿？真正厉害的，一定是在复杂业务系统里玩儿过高并发架构的人，但是你没有，那么我给你说一下你该怎么回答这个问题：</p><p>可以分为以下 6 点：</p><ul><li>系统拆分</li><li>缓存</li><li>MQ</li><li>分库分表</li><li>读写分离</li><li>ElasticSearch</li></ul><p><img src="https://i.loli.net/2020/05/28/UMDAq4sXIW6ybiQ.png" alt="high-concurrency-system-design.png"></p><h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是<strong>读多写少</strong>，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的<strong>读场景，怎么用缓存来抗高并发</strong>。</p><h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，<strong>后边系统消费后慢慢写</strong>，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表<strong>拆分为多个表</strong>，每个表的数据量保持少一点，提高 sql 跑的性能。</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，<strong>主库写</strong>入，<strong>从库读</strong>取，搞一个读写分离。<strong>读流量太多</strong>的时候，还可以<strong>加更多的从库</strong>。</p><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 es。es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p><p>上面的 6 点，基本就是高并发系统肯定要干的一些事儿，大家可以仔细结合之前讲过的知识考虑一下，到时候你可以系统的把这块阐述一下，然后每个部分要注意哪些问题，之前都讲过了，你都可以阐述阐述，表明你对这块是有点积累的。</p><p>说句实话，毕竟你真正厉害的一点，不是在于弄明白一些技术，或者大概知道一个高并发系统应该长什么样？其实实际上在真正的复杂的业务系统里，做高并发要远远比上面提到的点要复杂几十倍到上百倍。你需要考虑：哪些需要分库分表，哪些不需要分库分表，单库单表跟分库分表如何 join，哪些数据要放到缓存里去，放哪些数据才可以扛住高并发的请求，你需要完成对一个复杂业务系统的分析之后，然后逐步逐步的加入高并发的系统架构的改造，这个过程是无比复杂的，一旦做过一次，并且做好了，你在这个市场上就会非常的吃香。</p><p>其实大部分公司，真正看重的，不是说你掌握高并发相关的一些基本的架构知识，架构中的一些技术，RocketMQ、Kafka、Redis、Elasticsearch，高并发这一块，你了解了，也只能是次一等的人才。对一个有几十万行代码的复杂的分布式系统，一步一步架构、设计以及实践过高并发架构的人，这个经验是难能可贵的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何设计一个高并发系统？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;说实话，如果面试官问你这个题目，那么你必须要使出全身吃奶劲了。为啥？因为你没看到现在很多公司招聘的 JD 里都是说啥，有高并发就经验者优先。&lt;/p&gt;
&lt;p&gt;如果你确实有真才实学，在互联网公司里干过高并发系统，那你确实拿 offer 基本如探囊取物，没啥问题。面试官也绝对不会这样来问你，否则他就是蠢。&lt;/p&gt;
&lt;p&gt;假设你在某知名电商公司干过高并发系统，用户上亿，一天流量几十亿，高峰期并发量上万，甚至是十万。那么人家一定会仔细盘问你的系统架构，你们系统啥架构？怎么部署的？部署了多少台机器？缓存咋用的？MQ 咋用的？数据库咋用的？就是深挖你到底是如何扛住高并发的。&lt;/p&gt;
&lt;p&gt;因为真正干过高并发的人一定知道，脱离了业务的系统架构都是在纸上谈兵，真正在复杂业务场景而且还高并发的时候，那系统架构一定不是那么简单的，用个 redis，用 mq 就能搞定？当然不是，真实的系统架构搭配上业务之后，会比这种简单的所谓“高并发架构”要复杂很多倍。&lt;/p&gt;
&lt;p&gt;如果有面试官问你个问题说，如何设计一个高并发系统？那么不好意思，&lt;strong&gt;一定是因为你实际上没干过高并发系统&lt;/strong&gt;。面试官看你简历就没啥出彩的，感觉就不咋地，所以就会问问你，如何设计一个高并发系统？其实说白了本质就是看看你有没有自己研究过，有没有一定的知识积累。&lt;/p&gt;
&lt;p&gt;最好的当然是招聘个真正干过高并发的哥儿们咯，但是这种哥儿们人数稀缺，不好招。所以可能次一点的就是招一个自己研究过的哥儿们，总比招一个啥也不会的哥儿们好吧！&lt;/p&gt;
&lt;p&gt;所以这个时候你必须得做一把个人秀了，秀出你所有关于高并发的知识！&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="高并发" scheme="http://shenshanlaoyuan.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>如何实现 MySQL 的读写分离？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/27/%E9%9D%A2%E8%AF%95/2020-5-27-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0-MySQL-%E7%9A%84%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/27/面试/2020-5-27-如何实现-MySQL-的读写分离？/</id>
    <published>2020-05-27T03:52:00.000Z</published>
    <updated>2020-05-29T03:06:12.495Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>高并发这个阶段，肯定是需要做读写分离的，啥意思？因为实际上大部分的互联网公司，一些网站，或者是 app，其实都是读多写少。所以针对这个情况，就是写一个主库，但是主库挂多个从库，然后从多个从库来读，那不就可以支撑更高的读并发压力了吗？</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/27/面试/2020-5-27-如何实现-MySQL-的读写分离？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/27/面试/2020-5-27-如何实现-MySQL-的读写分离？/'>如何实现 MySQL 的读写分离？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="如何实现-MySQL-的读写分离？"><a href="#如何实现-MySQL-的读写分离？" class="headerlink" title="如何实现 MySQL 的读写分离？"></a>如何实现 MySQL 的读写分离？</h3><p>其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。</p><h3 id="MySQL-主从复制原理的是啥？"><a href="#MySQL-主从复制原理的是啥？" class="headerlink" title="MySQL 主从复制原理的是啥？"></a>MySQL 主从复制原理的是啥？</h3><p>主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。</p><p><img src="https://s1.ax1x.com/2020/05/28/tVTghj.png" alt="tVTghj.png"></p><p>这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是<strong>有延时</strong>的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。</p><p>而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。</p><p>所以 MySQL 实际上在这一块有两个机制，一个是<strong>半同步复制</strong>，用来解决主库数据丢失问题；一个是<strong>并行复制</strong>，用来解决主从同步延时问题。</p><p>这个所谓<strong>半同步复制</strong>，也叫 <code>semi-sync</code> 复制，指的就是主库写入 binlog 日志之后，就会将<strong>强制</strong>此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到<strong>至少一个从库</strong>的 ack 之后才会认为写操作完成了。</p><p>所谓<strong>并行复制</strong>，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后<strong>并行重放不同库的日志</strong>，这是库级别的并行。</p><h3 id="MySQL-主从同步延时问题（精华）"><a href="#MySQL-主从同步延时问题（精华）" class="headerlink" title="MySQL 主从同步延时问题（精华）"></a>MySQL 主从同步延时问题（精华）</h3><p>以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。</p><p>是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。</p><p>我们通过 MySQL 命令：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">show</span> <span class="keyword">status</span></div></pre></td></tr></table></figure></p><p>查看 <code>Seconds_Behind_Master</code>，可以看到从库复制主库的数据落后了几 ms。</p><p>一般来说，如果主从延迟较为严重，有以下解决方案：</p><ul><li>分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。</li><li>打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。</li><li>重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。</li><li>如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询<strong>设置直连主库</strong>。<strong>不推荐</strong>这种方法，你要是这么搞，读写分离的意义就丧失了。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;高并发这个阶段，肯定是需要做读写分离的，啥意思？因为实际上大部分的互联网公司，一些网站，或者是 app，其实都是读多写少。所以针对这个情况，就是写一个主库，但是主库挂多个从库，然后从多个从库来读，那不就可以支撑更高的读并发压力了吗？&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="MYSQL" scheme="http://shenshanlaoyuan.com/tags/MYSQL/"/>
    
      <category term="读写分离" scheme="http://shenshanlaoyuan.com/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    
  </entry>
  
  <entry>
    <title>分库分表之后，id 主键如何处理？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/26/%E9%9D%A2%E8%AF%95/2020-5-26-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%B9%8B%E5%90%8E%EF%BC%8Cid-%E4%B8%BB%E9%94%AE%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/26/面试/2020-5-26-分库分表之后，id-主键如何处理？/</id>
    <published>2020-05-26T03:52:00.000Z</published>
    <updated>2020-05-29T03:04:39.567Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>分库分表之后，id 主键如何处理？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个<strong>全局唯一</strong>的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/26/面试/2020-5-26-分库分表之后，id-主键如何处理？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/26/面试/2020-5-26-分库分表之后，id-主键如何处理？/'>分库分表之后，id 主键如何处理？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="基于数据库的实现方案"><a href="#基于数据库的实现方案" class="headerlink" title="基于数据库的实现方案"></a>基于数据库的实现方案</h3><h4 id="数据库自增-id"><a href="#数据库自增-id" class="headerlink" title="数据库自增 id"></a>数据库自增 id</h4><p>这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。</p><p>这个方案的好处就是方便简单，谁都会用；<strong>缺点就是单库生成</strong>自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是<strong>无论如何都是基于单个数据库</strong>。</p><p><strong>适合的场景</strong>：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你<strong>并发不高，但是数据量太大</strong>导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。</p><h4 id="设置数据库-sequence-或者表自增字段步长"><a href="#设置数据库-sequence-或者表自增字段步长" class="headerlink" title="设置数据库 sequence 或者表自增字段步长"></a>设置数据库 sequence 或者表自增字段步长</h4><p>可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。</p><p>比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。</p><p><img src="https://i.loli.net/2020/05/28/xhX5yzpwB4QN9M3.png" alt="database-id-sequence-step.png"></p><p><strong>适合的场景</strong>：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。</p><h3 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h3><p>好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，<strong>作为主键性能太差</strong>了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。</p><p>适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">UUID.randomUUID().toString().replace(<span class="string">"-"</span>, <span class="string">""</span>) -&gt; sfsdf23423rr234sfdaf</div></pre></td></tr></table></figure><h3 id="获取系统当前时间"><a href="#获取系统当前时间" class="headerlink" title="获取系统当前时间"></a>获取系统当前时间</h3><p>这个就是获取当前时间即可，但是问题是，<strong>并发很高的时候</strong>，比如一秒并发几千，<strong>会有重复的情况</strong>，这个是肯定不合适的。基本就不用考虑了。</p><p>适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。</p><h3 id="snowflake-算法"><a href="#snowflake-算法" class="headerlink" title="snowflake 算法"></a>snowflake 算法</h3><p>snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。</p><ul><li>1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。</li><li>41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 <code>2^41 - 1</code>，也就是可以标识 <code>2^41 - 1</code> 个毫秒值，换算成年就是表示69年的时间。</li><li>10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 <code>2^5</code>个机房（32个机房），每个机房里可以代表 <code>2^5</code> 个机器（32台机器）。</li><li>12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 <code>2^12 - 1 = 4096</code>，也就是说可以用这个 12 bit 代表的数字来区分<strong>同一个毫秒内</strong>的 4096 个不同的 id。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000</div></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IdWorker</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerId;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterId;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequence;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IdWorker</span><span class="params">(<span class="keyword">long</span> workerId, <span class="keyword">long</span> datacenterId, <span class="keyword">long</span> sequence)</span> </span>&#123;</div><div class="line">        <span class="comment">// sanity check for workerId</span></div><div class="line">        <span class="comment">// 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0</span></div><div class="line">        <span class="keyword">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</div><div class="line">                    String.format(<span class="string">"worker Id can't be greater than %d or less than 0"</span>, maxWorkerId));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</div><div class="line">                    String.format(<span class="string">"datacenter Id can't be greater than %d or less than 0"</span>, maxDatacenterId));</div><div class="line">        &#125;</div><div class="line">        System.out.printf(</div><div class="line">                <span class="string">"worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d"</span>,</div><div class="line">                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);</div><div class="line"></div><div class="line">        <span class="keyword">this</span>.workerId = workerId;</div><div class="line">        <span class="keyword">this</span>.datacenterId = datacenterId;</div><div class="line">        <span class="keyword">this</span>.sequence = sequence;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> twepoch = <span class="number">1288834974657L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerIdBits = <span class="number">5L</span>;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdBits = <span class="number">5L</span>;</div><div class="line"></div><div class="line">    <span class="comment">// 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> maxWorkerId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; workerIdBits);</div><div class="line"></div><div class="line">    <span class="comment">// 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> maxDatacenterId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; datacenterIdBits);</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequenceBits = <span class="number">12L</span>;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerIdShift = sequenceBits;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdShift = sequenceBits + workerIdBits;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequenceMask = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; sequenceBits);</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">long</span> lastTimestamp = -<span class="number">1L</span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getWorkerId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> workerId;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getDatacenterId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> datacenterId;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getTimestamp</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> System.currentTimeMillis();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">// 这儿就是获取当前时间戳，单位是毫秒</span></div><div class="line">        <span class="keyword">long</span> timestamp = timeGen();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (timestamp &lt; lastTimestamp) &#123;</div><div class="line">            System.err.printf(<span class="string">"clock is moving backwards.  Rejecting requests until %d."</span>, lastTimestamp);</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(String.format(</div><div class="line">                    <span class="string">"Clock moved backwards.  Refusing to generate id for %d milliseconds"</span>, lastTimestamp - timestamp));</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (lastTimestamp == timestamp) &#123;</div><div class="line">            <span class="comment">// 这个意思是说一个毫秒内最多只能有4096个数字</span></div><div class="line">            <span class="comment">// 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围</span></div><div class="line">            sequence = (sequence + <span class="number">1</span>) &amp; sequenceMask;</div><div class="line">            <span class="keyword">if</span> (sequence == <span class="number">0</span>) &#123;</div><div class="line">                timestamp = tilNextMillis(lastTimestamp);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            sequence = <span class="number">0</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 这儿记录一下最近一次生成id的时间戳，单位是毫秒</span></div><div class="line">        lastTimestamp = timestamp;</div><div class="line"></div><div class="line">        <span class="comment">// 这儿就是将时间戳左移，放到 41 bit那儿；</span></div><div class="line">        <span class="comment">// 将机房 id左移放到 5 bit那儿；</span></div><div class="line">        <span class="comment">// 将机器id左移放到5 bit那儿；将序号放最后12 bit；</span></div><div class="line">        <span class="comment">// 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型</span></div><div class="line">        <span class="keyword">return</span> ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift)</div><div class="line">                | (workerId &lt;&lt; workerIdShift) | sequence;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">tilNextMillis</span><span class="params">(<span class="keyword">long</span> lastTimestamp)</span> </span>&#123;</div><div class="line">        <span class="keyword">long</span> timestamp = timeGen();</div><div class="line">        <span class="keyword">while</span> (timestamp &lt;= lastTimestamp) &#123;</div><div class="line">            timestamp = timeGen();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> timestamp;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">timeGen</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> System.currentTimeMillis();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// ---------------测试---------------</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        IdWorker worker = <span class="keyword">new</span> IdWorker(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">30</span>; i++) &#123;</div><div class="line">            System.out.println(worker.nextId());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure><p>怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个<strong>机房</strong> id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的<strong>机器</strong> id（但是最大只能是 32 以内），剩下的那个 12 bit序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。</p><p>所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。</p><p>利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。</p><p>这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;分库分表之后，id 主键如何处理？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个&lt;strong&gt;全局唯一&lt;/strong&gt;的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>如何设计可以动态扩容缩容的分库分表方案？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/25/%E9%9D%A2%E8%AF%95/2020-5-25-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%8F%AF%E4%BB%A5%E5%8A%A8%E6%80%81%E6%89%A9%E5%AE%B9%E7%BC%A9%E5%AE%B9%E7%9A%84%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/25/面试/2020-5-25-如何设计可以动态扩容缩容的分库分表方案？/</id>
    <published>2020-05-25T03:52:00.000Z</published>
    <updated>2020-05-29T03:03:24.022Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何设计可以动态扩容缩容的分库分表方案？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>对于分库分表来说，主要是面对以下问题：</p><ul><li>选择一个数据库中间件，调研、学习、测试；</li><li>设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；</li><li>基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；</li><li>完成单库单表到分库分表的<strong>迁移</strong>，双写方案；</li><li>线上系统开始基于分库分表对外提供服务；</li><li>扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？</li></ul><p>这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。</p><p>那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。</p><p>这都是玩儿分库分表线上必须经历的事儿。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/25/面试/2020-5-25-如何设计可以动态扩容缩容的分库分表方案？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/25/面试/2020-5-25-如何设计可以动态扩容缩容的分库分表方案？/'>如何设计可以动态扩容缩容的分库分表方案？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="停机扩容（不推荐）"><a href="#停机扩容（不推荐）" class="headerlink" title="停机扩容（不推荐）"></a>停机扩容（不推荐）</h3><p>这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然<strong>分库分表</strong>就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。</p><p>从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1小时数据就导完了。这没有问题。</p><p>如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。</p><h3 id="优化后的方案"><a href="#优化后的方案" class="headerlink" title="优化后的方案"></a>优化后的方案</h3><p>一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。</p><p>我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。</p><p>每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 <em> 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 </em> 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。</p><p>有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。</p><p>1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。</p><p>每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。</p><p>谈分库分表的扩容，<strong>第一次分库分表，就一次性给他分个够</strong>，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。</p><p>一个实践是利用 <code>32 * 32</code> 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。</p><table><thead><tr><th>orderId</th><th>id % 32 (库)</th><th>id / 32 % 32 (表)</th></tr></thead><tbody><tr><td>259</td><td>3</td><td>8</td></tr><tr><td>1189</td><td>5</td><td>5</td></tr><tr><td>352</td><td>0</td><td>11</td></tr><tr><td>4593</td><td>17</td><td>15</td></tr></tbody></table><p>刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 mysql 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 mysql 服务器之间做迁移就可以了。然后系统配合改一下配置即可。</p><p>比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。</p><p>这么搞，是不用自己写代码做数据迁移的，都交给 dba 来搞好了，但是 dba 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。</p><p>哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。</p><p>这里对步骤做一个总结：</p><ol><li>设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。</li><li>路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表</li><li>扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。</li><li>由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。</li><li>我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。</li><li>重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何设计可以动态扩容缩容的分库分表方案？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;对于分库分表来说，主要是面对以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选择一个数据库中间件，调研、学习、测试；&lt;/li&gt;
&lt;li&gt;设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；&lt;/li&gt;
&lt;li&gt;基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；&lt;/li&gt;
&lt;li&gt;完成单库单表到分库分表的&lt;strong&gt;迁移&lt;/strong&gt;，双写方案；&lt;/li&gt;
&lt;li&gt;线上系统开始基于分库分表对外提供服务；&lt;/li&gt;
&lt;li&gt;扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。&lt;/p&gt;
&lt;p&gt;那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。&lt;/p&gt;
&lt;p&gt;这都是玩儿分库分表线上必须经历的事儿。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>分库分表如何平滑过渡？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/24/%E9%9D%A2%E8%AF%95/2020-5-24-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%A6%82%E4%BD%95%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/24/面试/2020-5-24-分库分表如何平滑过渡？/</id>
    <published>2020-05-24T03:52:00.000Z</published>
    <updated>2020-05-29T03:01:55.918Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表<strong>动态切换</strong>到分库分表上？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？</p><p>所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/24/面试/2020-5-24-分库分表如何平滑过渡？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/24/面试/2020-5-24-分库分表如何平滑过渡？/'>分库分表如何平滑过渡？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。</p><h3 id="停机迁移方案"><a href="#停机迁移方案" class="headerlink" title="停机迁移方案"></a>停机迁移方案</h3><p>我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。</p><p>接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个<strong>导数的一次性工具</strong>，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。</p><p>导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。</p><p>验证一下，ok了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。</p><p>但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。</p><p><img src="https://i.loli.net/2020/05/28/VF8JKwYEfyu6H9v.png" alt="database-shard-method-1.png"></p><h3 id="双写迁移方案"><a href="#双写迁移方案" class="headerlink" title="双写迁移方案"></a>双写迁移方案</h3><p>这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。</p><p>简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，<strong>除了对老库增删改，都加上对新库的增删改</strong>，这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</p><p>然后<strong>系统部署</strong>之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。</p><p>导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。</p><p>接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。</p><p><img src="https://i.loli.net/2020/05/28/YkvqeFGnUxZPVyI.png" alt="database-shard-method-2.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表&lt;strong&gt;动态切换&lt;/strong&gt;到分库分表上？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？&lt;/p&gt;
&lt;p&gt;所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>为什么要分库分表？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/23/%E9%9D%A2%E8%AF%95/2020-5-23-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/23/面试/2020-5-23-为什么要分库分表？/</id>
    <published>2020-05-23T03:52:00.000Z</published>
    <updated>2020-05-29T03:00:14.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这块肯定是扯到<strong>高并发</strong>了，因为分库分表一定是为了<strong>支撑高并发、数据量大</strong>两个问题的。而且现在说实话，尤其是互联网类的公司面试，基本上都会来这么一下，分库分表如此普遍的技术问题，不问实在是不行，而如果你不知道那也实在是说不过去！</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/23/面试/2020-5-23-为什么要分库分表？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/23/面试/2020-5-23-为什么要分库分表？/'>为什么要分库分表？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"><a href="#为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）" class="headerlink" title="为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"></a>为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）</h3><p>说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。</p><p>我先给大家抛出来一个场景。</p><p>假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。我的天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。</p><p>结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！</p><p>好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢……</p><p>再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。</p><p>但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 <code>5000~8000</code>！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！</p><p>好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。</p><h4 id="分表"><a href="#分表" class="headerlink" title="分表"></a>分表</h4><p>比如你单表都几千万数据了，你确定你能扛住么？绝对不行，<strong>单表数据量太大</strong>，会极大影响你的 sql <strong>执行的性能</strong>，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p><p>分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p><h4 id="分库"><a href="#分库" class="headerlink" title="分库"></a>分库</h4><p>分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p><p>这就是所谓的<strong>分库分表</strong>，为啥要分库分表？你明白了吧。</p><table><thead><tr><th>#</th><th>分库分表前</th><th>分库分表后</th></tr></thead><tbody><tr><td>并发支撑情况</td><td>MySQL 单机部署，扛不住高并发</td><td>MySQL从单机到多机，能承受的并发增加了多倍</td></tr><tr><td>磁盘使用情况</td><td>MySQL 单机磁盘容量几乎撑满</td><td>拆分为多个库，数据库服务器磁盘使用率大大降低</td></tr><tr><td>SQL 执行性能</td><td>单表数据量太大，SQL 越跑越慢</td><td>单表数据量减少，SQL 执行效率明显提升</td></tr></tbody></table><h3 id="用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"><a href="#用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？" class="headerlink" title="用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"></a>用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</h3><p>这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。</p><p>比较常见的包括：</p><ul><li>Cobar</li><li>TDDL</li><li>Atlas</li><li>Sharding-jdbc</li><li>Mycat</li></ul><h4 id="Cobar"><a href="#Cobar" class="headerlink" title="Cobar"></a>Cobar</h4><p>阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p><h4 id="TDDL"><a href="#TDDL" class="headerlink" title="TDDL"></a>TDDL</h4><p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p><h4 id="Atlas"><a href="#Atlas" class="headerlink" title="Atlas"></a>Atlas</h4><p>360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p><h4 id="Sharding-jdbc"><a href="#Sharding-jdbc" class="headerlink" title="Sharding-jdbc"></a>Sharding-jdbc</h4><p>当当开源的，属于 client 层方案，是<a href="https://shardingsphere.apache.org" target="_blank" rel="external"><code>ShardingSphere</code></a>的 client 层方案，<a href="https://shardingsphere.apache.org" target="_blank" rel="external"><code>ShardingSphere</code></a>还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 <code>4.0.0-RC1</code> 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</p><h4 id="Mycat"><a href="#Mycat" class="headerlink" title="Mycat"></a>Mycat</h4><p>基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。</p><p>Sharding-jdbc 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> Sharding-jdbc 的依赖；</p><p>Mycat 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了。</p><p>通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。</p><h3 id="你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"><a href="#你们具体是如何对数据库如何进行垂直拆分或水平拆分的？" class="headerlink" title="你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"></a>你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</h3><p><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。</p><p><img src="https://i.loli.net/2020/05/23/9Y3I1foGaXieW4v.png" alt="database-split-horizon.png"></p><p><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p><p><img src="https://i.loli.net/2020/05/23/hXmae7uzn4wijyR.png" alt="database-split-vertically.png"></p><p>这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。</p><p>还有<strong>表层面的拆分</strong>，就是分表，将一个表变成 N 个表，就是<strong>让每个表的数据量控制在一定范围内</strong>，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。</p><p>好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，<strong>中间件可以根据你指定的某个字段值</strong>，比如说 userid，<strong>自动路由到对应的库上去，然后再自动路由到对应的表里去</strong>。</p><p>你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。</p><p>而且这儿还有两种<strong>分库分表的方式</strong>：</p><ul><li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li><li>或者是按照某个字段 hash 一下均匀分散，这个较为常用。</li></ul><p>range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</p><p>hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实这块肯定是扯到&lt;strong&gt;高并发&lt;/strong&gt;了，因为分库分表一定是为了&lt;strong&gt;支撑高并发、数据量大&lt;/strong&gt;两个问题的。而且现在说实话，尤其是互联网类的公司面试，基本上都会来这么一下，分库分表如此普遍的技术问题，不问实在是不行，而如果你不知道那也实在是说不过去！&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="分库分表" scheme="http://shenshanlaoyuan.com/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>生产环境中的Redis是怎么部署的？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/22/%E9%9D%A2%E8%AF%95/2020-5-22-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84Redis%E6%98%AF%E6%80%8E%E4%B9%88%E9%83%A8%E7%BD%B2%E7%9A%84%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/22/面试/2020-5-22-生产环境中的Redis是怎么部署的？/</id>
    <published>2020-05-22T03:52:00.000Z</published>
    <updated>2020-05-09T06:45:52.772Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>生产环境中的 redis 是怎么部署的？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>看看你了解不了解你们公司的 redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你的 redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确保可以进行数据恢复？线上 redis 给几个 G 的内存？设置了哪些参数？压测后你们 redis 集群承载多少 QPS？</p><p>兄弟，这些你必须是门儿清的，否则你确实是没好好思考过。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/22/面试/2020-5-22-生产环境中的Redis是怎么部署的？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/22/面试/2020-5-22-生产环境中的Redis是怎么部署的？/'>生产环境中的Redis是怎么部署的？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。</p><p>机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p><p>5 台机器对外提供读写，一共有 50g 内存。</p><p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p><p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p><p>其实大型的公司，会有基础架构的 team 负责缓存集群的运维。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;生产环境中的 redis 是怎么部署的？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;看看你了解不了解你们公司的 redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你的 redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确保可以进行数据恢复？线上 redis 给几个 G 的内存？设置了哪些参数？压测后你们 redis 集群承载多少 QPS？&lt;/p&gt;
&lt;p&gt;兄弟，这些你必须是门儿清的，否则你确实是没好好思考过。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>如何解决Redis的并发竞争问题？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/21/%E9%9D%A2%E8%AF%95/2020-5-21-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3Redis%E7%9A%84%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E9%97%AE%E9%A2%98%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/21/面试/2020-5-21-如何解决Redis的并发竞争问题？/</id>
    <published>2020-05-21T03:52:00.000Z</published>
    <updated>2020-05-09T06:44:36.277Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个也是线上非常常见的一个问题，就是<strong>多客户端同时并发写</strong>一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。</p><p>而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/21/面试/2020-5-21-如何解决Redis的并发竞争问题？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/21/面试/2020-5-21-如何解决Redis的并发竞争问题？/'>如何解决Redis的并发竞争问题？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。</p><p><img src="https://i.loli.net/2020/05/09/ZKFW4tc5nhJIb1D.png" alt="zookeeper-distributed-lock.png"></p><p>你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。</p><p>每次要<strong>写之前，先判断</strong>一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个也是线上非常常见的一个问题，就是&lt;strong&gt;多客户端同时并发写&lt;/strong&gt;一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。&lt;/p&gt;
&lt;p&gt;而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>如何保证缓存与数据库双写一致性？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/20/%E9%9D%A2%E8%AF%95/2020-5-20-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/20/面试/2020-5-20-如何保证缓存与数据库双写一致性？/</id>
    <published>2020-05-20T03:52:00.000Z</published>
    <updated>2020-05-09T06:43:21.713Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证缓存与数据库的双写一致性？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p><p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/20/面试/2020-5-20-如何保证缓存与数据库双写一致性？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/20/面试/2020-5-20-如何保证缓存与数据库双写一致性？/'>如何保证缓存与数据库双写一致性？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h3 id="Cache-Aside-Pattern"><a href="#Cache-Aside-Pattern" class="headerlink" title="Cache Aside Pattern"></a>Cache Aside Pattern</h3><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p><ul><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li></ul><p><strong>为什么是删除缓存，而不是更新缓存？</strong></p><p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p><p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p><p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p><p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p><p>其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都把里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p><h3 id="最初级的缓存不一致问题及解决方案"><a href="#最初级的缓存不一致问题及解决方案" class="headerlink" title="最初级的缓存不一致问题及解决方案"></a>最初级的缓存不一致问题及解决方案</h3><p>问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p><p><img src="https://i.loli.net/2020/05/09/eQzLxlaiW1HbSOu.png" alt="redis-junior-inconsistent.png"></p><p>解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p><h3 id="比较复杂的数据不一致问题分析"><a href="#比较复杂的数据不一致问题分析" class="headerlink" title="比较复杂的数据不一致问题分析"></a>比较复杂的数据不一致问题分析</h3><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了…</p><p><strong>为什么上亿流量高并发场景下，缓存会出现这个问题？</strong></p><p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就<strong>可能会出现上述的数据库+缓存不一致的情况</strong>。</p><p><strong>解决方案如下：</strong></p><p>更新数据的时候，根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个 jvm 内部队列中。</p><p>一个队列对应一个工作线程，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p><p>这里有一个<strong>优化点</strong>，一个队列中，其实<strong>多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p><p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p><p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。</p><p>高并发的场景下，该解决方案要注意的问题：</p><ul><li>读请求长时阻塞</li></ul><p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。</p><p>该解决方案，最大的风险点在于说，<strong>可能数据更新很频繁</strong>，导致队列中积压了大量更新操作在里面，然后<strong>读请求会发生大量的超时</strong>，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。</p><p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要<strong>部署多个服务</strong>，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 <em> 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致<em>*读请求的长时阻塞</em></em>。</p><p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。</p><p><strong>如果一个内存队列中可能积压的更新操作特别多</strong>，那么你就要<strong>加机器</strong>，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。</p><p>其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。</p><p>我们来<strong>实际粗略测算一下</strong>。</p><p>如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。</p><p>经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。</p><ul><li>读请求并发量过高</li></ul><p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。</p><p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。</p><ul><li>多服务实例部署的请求路由</li></ul><p>可能这个服务部署了多个实例，那么必须<strong>保证</strong>说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器<strong>路由到相同的服务实例上</strong>。</p><p>比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。</p><ul><li>热点商品的路由问题，导致请求的倾斜</li></ul><p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何保证缓存与数据库的双写一致性？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？&lt;/p&gt;
&lt;h2 id=&quot;面试题剖析&quot;&gt;&lt;a href=&quot;#面试题剖析&quot; class=&quot;headerlink&quot; title=&quot;面试题剖析&quot;&gt;&lt;/a&gt;面试题剖析&lt;/h2&gt;&lt;p&gt;一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统&lt;strong&gt;不是严格要求&lt;/strong&gt; “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：&lt;strong&gt;读请求和写请求串行化&lt;/strong&gt;，串到一个&lt;strong&gt;内存队列&lt;/strong&gt;里去。&lt;/p&gt;
&lt;p&gt;串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis的雪崩、穿透和击穿，如何应对？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/19/%E9%9D%A2%E8%AF%95/2020-5-19-redis%E7%9A%84%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E5%92%8C%E5%87%BB%E7%A9%BF%EF%BC%8C%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/19/面试/2020-5-19-redis的雪崩、穿透和击穿，如何应对？/</id>
    <published>2020-05-19T03:52:00.000Z</published>
    <updated>2020-05-09T06:41:56.659Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/19/面试/2020-5-19-redis的雪崩、穿透和击穿，如何应对？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/19/面试/2020-5-19-redis的雪崩、穿透和击穿，如何应对？/'>redis的雪崩、穿透和击穿，如何应对？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p><p>这就是缓存雪崩。</p><p><img src="https://i.loli.net/2020/05/09/fdJ2wZzrlkbDHeL.png" alt="redis-caching-avalanche.png"></p><p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p><p>缓存雪崩的事前事中事后的解决方案如下：</p><ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><p><img src="https://i.loli.net/2020/05/09/hiZDFAvIx5JNMqm.png" alt="redis-caching-avalanche-solution.png"></p><p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。</p><p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空值。</p><p>好处：</p><ul><li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li><li>只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。</li><li>只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。</li></ul><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><p><img src="https://i.loli.net/2020/05/09/2Mvu5sJjlQOS6YK.png" alt="redis-caching-penetration.png"></p><p>解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</p><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><p>不同场景下的解决方式可如下：</p><ul><li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li><li>若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="消息队列" scheme="http://shenshanlaoyuan.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Redis集群模式的工作原理能说一下么？</title>
    <link href="http://shenshanlaoyuan.com/2020/05/18/%E9%9D%A2%E8%AF%95/2020-5-18-Redis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E8%83%BD%E8%AF%B4%E4%B8%80%E4%B8%8B%E4%B9%88%EF%BC%9F/"/>
    <id>http://shenshanlaoyuan.com/2020/05/18/面试/2020-5-18-Redis集群模式的工作原理能说一下么？/</id>
    <published>2020-05-18T03:52:00.000Z</published>
    <updated>2020-05-09T06:40:21.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得<strong>借助一些中间件</strong>来实现，比如说有 <code>codis</code>，或者 <code>twemproxy</code>，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。</p><p>这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。</p><p>现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。</p><p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。</p><p>redis cluster，主要是针对<strong>海量数据+高并发+高可用</strong>的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。</p><a id="more"></a><span class='source'><blockquote><p>转载请注明出处：http://shenshanlaoyuan.com/2020/05/18/面试/2020-5-18-Redis集群模式的工作原理能说一下么？/</p><p>访问原文「<a href='http://shenshanlaoyuan.com/2020/05/18/面试/2020-5-18-Redis集群模式的工作原理能说一下么？/'>Redis集群模式的工作原理能说一下么？</a>」获取最佳阅读体验并参与讨论</p></blockquote></span><script type="text/javascript">(function() {  Element.prototype.remove = function() {    this.parentElement.removeChild(this);  }  NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }  }  var domain = document.domain;  var white_list = ['shenshanlaoyuan.com', 'localhost'];  if (white_list.indexOf(domain) >= 0) {    var elements = document.getElementsByClassName('source');    elements.remove();  }})()</script> <h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-cluster-介绍"><a href="#redis-cluster-介绍" class="headerlink" title="redis cluster 介绍"></a>redis cluster 介绍</h3><ul><li>自动将数据进行分片，每个 master 上放一部分数据</li><li>提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的</li></ul><p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。</p><p>16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，<code>gossip</code> 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p><h3 id="节点间的内部通信机制"><a href="#节点间的内部通信机制" class="headerlink" title="节点间的内部通信机制"></a>节点间的内部通信机制</h3><h4 id="基本通信原理"><a href="#基本通信原理" class="headerlink" title="基本通信原理"></a>基本通信原理</h4><p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p><p><strong>集中式</strong>是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 <code>storm</code>。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><p><img src="https://i.loli.net/2020/05/09/tTmNvnj5HMQfuGq.png" alt="zookeeper-centralized-storage.png"></p><p>redis 维护集群元数据采用另一个方式， <code>gossip</code> 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><p><img src="https://i.loli.net/2020/05/09/KSLQupvrWTXxmoH.png" alt="redis-gossip.png"></p><p><strong>集中式</strong>的<strong>好处</strong>在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；<strong>不好</strong>在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</p><p>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p><ul><li><p>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 <code>ping</code> 消息，同时其它几个节点接收到 <code>ping</code> 之后返回 <code>pong</code>。</p></li><li><p>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</p></li></ul><h4 id="gossip-协议"><a href="#gossip-协议" class="headerlink" title="gossip 协议"></a>gossip 协议</h4><p>gossip 协议包含多种消息，包含 <code>ping</code>,<code>pong</code>,<code>meet</code>,<code>fail</code> 等等。</p><ul><li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">redis-trib.rb add-node</div></pre></td></tr></table></figure><p>其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。</p><ul><li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</li><li>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</li><li>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</li></ul><h4 id="ping-消息深入"><a href="#ping-消息深入" class="headerlink" title="ping 消息深入"></a>ping 消息深入</h4><p>ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。</p><p>每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 <code>cluster_node_timeout / 2</code>，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 <code>cluster_node_timeout</code> 可以调节，如果调得比较大，那么会降低 ping 的频率。</p><p>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 <code>3</code> 个其它节点的信息，最多包含 <code>总节点数减 2</code> 个其它节点的信息。</p><h3 id="分布式寻址算法"><a href="#分布式寻址算法" class="headerlink" title="分布式寻址算法"></a>分布式寻址算法</h3><ul><li>hash 算法（大量缓存重建）</li><li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li><li>redis cluster 的 hash slot 算法</li></ul><h4 id="hash-算法"><a href="#hash-算法" class="headerlink" title="hash 算法"></a>hash 算法</h4><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致<strong>大部分的请求过来，全部无法拿到有效的缓存</strong>，导致大量的流量涌入数据库。</p><p><img src="https://i.loli.net/2020/05/09/KQxa1OE79g2TNsY.png" alt="hash.png"></p><h4 id="一致性-hash-算法"><a href="#一致性-hash-算法" class="headerlink" title="一致性 hash 算法"></a>一致性 hash 算法</h4><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。</p><p><img src="https://i.loli.net/2020/05/09/Rz9WVuLSrmhsTwE.png" alt="consistent-hashing-algorithm.png"></p><h4 id="redis-cluster-的-hash-slot-算法"><a href="#redis-cluster-的-hash-slot-算法" class="headerlink" title="redis cluster 的 hash slot 算法"></a>redis cluster 的 hash slot 算法</h4><p>redis cluster 有固定的 <code>16384</code> 个 hash slot，对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 key 对应的 hash slot。</p><p>redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <code>hash tag</code> 来实现。</p><p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。</p><p><img src="https://i.loli.net/2020/05/09/FYQdlar4cBx5mPJ.png" alt="hash-slot.png"></p><h3 id="redis-cluster-的高可用与主备切换原理"><a href="#redis-cluster-的高可用与主备切换原理" class="headerlink" title="redis cluster 的高可用与主备切换原理"></a>redis cluster 的高可用与主备切换原理</h3><p>redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p><h4 id="判断节点宕机"><a href="#判断节点宕机" class="headerlink" title="判断节点宕机"></a>判断节点宕机</h4><p>如果一个节点认为另外一个节点宕机，那么就是 <code>pfail</code>，<strong>主观宕机</strong>。如果多个节点都认为另外一个节点宕机了，那么就是 <code>fail</code>，<strong>客观宕机</strong>，跟哨兵的原理几乎一样，sdown，odown。</p><p>在 <code>cluster-node-timeout</code> 内，某个节点一直没有返回 <code>pong</code>，那么就被认为 <code>pfail</code>。</p><p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中，<code>ping</code> 给其他节点，如果<strong>超过半数</strong>的节点都认为 <code>pfail</code> 了，那么就会变成 <code>fail</code>。</p><h4 id="从节点过滤"><a href="#从节点过滤" class="headerlink" title="从节点过滤"></a>从节点过滤</h4><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p><p>检查每个 slave node 与 master node 断开连接的时间，如果超过了 <code>cluster-node-timeout * cluster-slave-validity-factor</code>，那么就<strong>没有资格</strong>切换成 <code>master</code>。</p><h4 id="从节点选举"><a href="#从节点选举" class="headerlink" title="从节点选举"></a>从节点选举</h4><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p><p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node<code>（N/2 + 1）</code>都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p><p>从节点执行主备切换，从节点切换为主节点。</p><h4 id="与哨兵比较"><a href="#与哨兵比较" class="headerlink" title="与哨兵比较"></a>与哨兵比较</h4><p>整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得&lt;strong&gt;借助一些中间件&lt;/strong&gt;来实现，比如说有 &lt;code&gt;codis&lt;/code&gt;，或者 &lt;code&gt;twemproxy&lt;/code&gt;，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。&lt;/p&gt;
&lt;p&gt;这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。&lt;/p&gt;
&lt;p&gt;现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。&lt;/p&gt;
&lt;p&gt;如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。&lt;/p&gt;
&lt;p&gt;redis cluster，主要是针对&lt;strong&gt;海量数据+高并发+高可用&lt;/strong&gt;的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。&lt;/p&gt;
    
    </summary>
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="http://shenshanlaoyuan.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="缓存" scheme="http://shenshanlaoyuan.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
</feed>
